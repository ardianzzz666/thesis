{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from pandas import concat\n",
    "from numpy import ndarray\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk merubah data menjadi supervised learning problem\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = pd.read_csv('data/new/case_maret_july.csv')\n",
    "case.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-18</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            case\n",
       "date            \n",
       "2020-03-18    38\n",
       "2020-03-19    50\n",
       "2020-03-20    14\n",
       "2020-03-21    44\n",
       "2020-03-22    36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil data untuk evaluasi\n",
    "data_evaluasi = case[413:]\n",
    "\n",
    "#total split data untuk LSTM\n",
    "n_total = 412\n",
    "\n",
    "#jumlah neuron\n",
    "neu = int(2/3*(n_total+1))\n",
    "jumlah_neuron = neu\n",
    "\n",
    "# Parameter untuk LSTM\n",
    "epooch_total = 1000\n",
    "size_batch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>38.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>50.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>14.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>44.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>36.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-10</th>\n",
       "      <td>809.0</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-11</th>\n",
       "      <td>694.0</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12</th>\n",
       "      <td>406.0</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-13</th>\n",
       "      <td>656.0</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>785.0</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            var1(t-1)  var1(t)\n",
       "date                          \n",
       "2020-03-19       38.0       50\n",
       "2020-03-20       50.0       14\n",
       "2020-03-21       14.0       44\n",
       "2020-03-22       44.0       36\n",
       "2020-03-23       36.0       51\n",
       "...               ...      ...\n",
       "2021-05-10      809.0      694\n",
       "2021-05-11      694.0      406\n",
       "2021-05-12      406.0      656\n",
       "2021-05-13      656.0      785\n",
       "2021-05-14      785.0      632\n",
       "\n",
       "[422 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ubah data menjadi supervised learning problem\n",
    "reframed = series_to_supervised(case, 1, 1)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 1, 1) (412,) (10, 1, 1) (10,)\n"
     ]
    }
   ],
   "source": [
    "# split data menjadi data train dan test\n",
    "values= reframed.values\n",
    "\n",
    "train = values[:n_total, :]\n",
    "test = values[n_total:, :]\n",
    "\n",
    "# split menjadi input dan output\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input menjadi [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "83/83 - 1s - loss: 991.3424 - val_loss: 711.8325\n",
      "Epoch 2/1000\n",
      "83/83 - 0s - loss: 974.5652 - val_loss: 690.9022\n",
      "Epoch 3/1000\n",
      "83/83 - 0s - loss: 956.8199 - val_loss: 673.7251\n",
      "Epoch 4/1000\n",
      "83/83 - 1s - loss: 940.7948 - val_loss: 657.7217\n",
      "Epoch 5/1000\n",
      "83/83 - 0s - loss: 927.2750 - val_loss: 643.8421\n",
      "Epoch 6/1000\n",
      "83/83 - 0s - loss: 915.9547 - val_loss: 631.0081\n",
      "Epoch 7/1000\n",
      "83/83 - 0s - loss: 906.0624 - val_loss: 618.9894\n",
      "Epoch 8/1000\n",
      "83/83 - 0s - loss: 897.2209 - val_loss: 607.5522\n",
      "Epoch 9/1000\n",
      "83/83 - 0s - loss: 889.8723 - val_loss: 597.2186\n",
      "Epoch 10/1000\n",
      "83/83 - 0s - loss: 885.7300 - val_loss: 591.7808\n",
      "Epoch 11/1000\n",
      "83/83 - 0s - loss: 884.4445 - val_loss: 590.2787\n",
      "Epoch 12/1000\n",
      "83/83 - 1s - loss: 877.9066 - val_loss: 581.1884\n",
      "Epoch 13/1000\n",
      "83/83 - 0s - loss: 877.8550 - val_loss: 580.9007\n",
      "Epoch 14/1000\n",
      "83/83 - 0s - loss: 877.6503 - val_loss: 579.0723\n",
      "Epoch 15/1000\n",
      "83/83 - 0s - loss: 876.6085 - val_loss: 579.8241\n",
      "Epoch 16/1000\n",
      "83/83 - 0s - loss: 879.3647 - val_loss: 583.2120\n",
      "Epoch 17/1000\n",
      "83/83 - 0s - loss: 881.3365 - val_loss: 586.4230\n",
      "Epoch 18/1000\n",
      "83/83 - 0s - loss: 876.3281 - val_loss: 580.3433\n",
      "Epoch 19/1000\n",
      "83/83 - 0s - loss: 881.4088 - val_loss: 587.1908\n",
      "Epoch 20/1000\n",
      "83/83 - 1s - loss: 876.5255 - val_loss: 580.7802\n",
      "Epoch 21/1000\n",
      "83/83 - 0s - loss: 882.6325 - val_loss: 588.9193\n",
      "Epoch 22/1000\n",
      "83/83 - 0s - loss: 877.7783 - val_loss: 582.9803\n",
      "Epoch 23/1000\n",
      "83/83 - 0s - loss: 883.0682 - val_loss: 590.4565\n",
      "Epoch 24/1000\n",
      "83/83 - 0s - loss: 878.7881 - val_loss: 584.7986\n",
      "Epoch 25/1000\n",
      "83/83 - 0s - loss: 884.4669 - val_loss: 591.9686\n",
      "Epoch 26/1000\n",
      "83/83 - 1s - loss: 880.5393 - val_loss: 587.2159\n",
      "Epoch 27/1000\n",
      "83/83 - 0s - loss: 878.3469 - val_loss: 584.3962\n",
      "Epoch 28/1000\n",
      "83/83 - 0s - loss: 874.8221 - val_loss: 579.2888\n",
      "Epoch 29/1000\n",
      "83/83 - 0s - loss: 874.3538 - val_loss: 579.4845\n",
      "Epoch 30/1000\n",
      "83/83 - 0s - loss: 871.8930 - val_loss: 574.5898\n",
      "Epoch 31/1000\n",
      "83/83 - 0s - loss: 867.7421 - val_loss: 570.5428\n",
      "Epoch 32/1000\n",
      "83/83 - 1s - loss: 867.8611 - val_loss: 567.6639\n",
      "Epoch 33/1000\n",
      "83/83 - 0s - loss: 867.4696 - val_loss: 569.1666\n",
      "Epoch 34/1000\n",
      "83/83 - 0s - loss: 871.0947 - val_loss: 571.9003\n",
      "Epoch 35/1000\n",
      "83/83 - 0s - loss: 867.7311 - val_loss: 570.1037\n",
      "Epoch 36/1000\n",
      "83/83 - 0s - loss: 867.5794 - val_loss: 567.5493\n",
      "Epoch 37/1000\n",
      "83/83 - 0s - loss: 867.1254 - val_loss: 569.1927\n",
      "Epoch 38/1000\n",
      "83/83 - 0s - loss: 866.6897 - val_loss: 566.7792\n",
      "Epoch 39/1000\n",
      "83/83 - 0s - loss: 862.7272 - val_loss: 563.5952\n",
      "Epoch 40/1000\n",
      "83/83 - 0s - loss: 861.9132 - val_loss: 559.4106\n",
      "Epoch 41/1000\n",
      "83/83 - 0s - loss: 858.3043 - val_loss: 557.0220\n",
      "Epoch 42/1000\n",
      "83/83 - 0s - loss: 860.0000 - val_loss: 555.7662\n",
      "Epoch 43/1000\n",
      "83/83 - 0s - loss: 854.2103 - val_loss: 551.4017\n",
      "Epoch 44/1000\n",
      "83/83 - 0s - loss: 861.3243 - val_loss: 556.8279\n",
      "Epoch 45/1000\n",
      "83/83 - 0s - loss: 859.0141 - val_loss: 557.9537\n",
      "Epoch 46/1000\n",
      "83/83 - 0s - loss: 858.4437 - val_loss: 554.3563\n",
      "Epoch 47/1000\n",
      "83/83 - 0s - loss: 857.0280 - val_loss: 555.4120\n",
      "Epoch 48/1000\n",
      "83/83 - 0s - loss: 857.4748 - val_loss: 552.6663\n",
      "Epoch 49/1000\n",
      "83/83 - 0s - loss: 852.2725 - val_loss: 549.1754\n",
      "Epoch 50/1000\n",
      "83/83 - 0s - loss: 852.9965 - val_loss: 545.8500\n",
      "Epoch 51/1000\n",
      "83/83 - 0s - loss: 847.5034 - val_loss: 543.0023\n",
      "Epoch 52/1000\n",
      "83/83 - 0s - loss: 851.4520 - val_loss: 543.0310\n",
      "Epoch 53/1000\n",
      "83/83 - 0s - loss: 846.7686 - val_loss: 541.8580\n",
      "Epoch 54/1000\n",
      "83/83 - 0s - loss: 848.5707 - val_loss: 538.8182\n",
      "Epoch 55/1000\n",
      "83/83 - 0s - loss: 841.5737 - val_loss: 534.8508\n",
      "Epoch 56/1000\n",
      "83/83 - 0s - loss: 846.9324 - val_loss: 534.7785\n",
      "Epoch 57/1000\n",
      "83/83 - 0s - loss: 838.8174 - val_loss: 530.8734\n",
      "Epoch 58/1000\n",
      "83/83 - 0s - loss: 848.6491 - val_loss: 536.7623\n",
      "Epoch 59/1000\n",
      "83/83 - 0s - loss: 840.3644 - val_loss: 532.8602\n",
      "Epoch 60/1000\n",
      "83/83 - 0s - loss: 847.8621 - val_loss: 536.2877\n",
      "Epoch 61/1000\n",
      "83/83 - 0s - loss: 840.3037 - val_loss: 533.3097\n",
      "Epoch 62/1000\n",
      "83/83 - 0s - loss: 843.3121 - val_loss: 530.5095\n",
      "Epoch 63/1000\n",
      "83/83 - 0s - loss: 835.6100 - val_loss: 526.8094\n",
      "Epoch 64/1000\n",
      "83/83 - 0s - loss: 839.8041 - val_loss: 524.0297\n",
      "Epoch 65/1000\n",
      "83/83 - 0s - loss: 831.3127 - val_loss: 520.7131\n",
      "Epoch 66/1000\n",
      "83/83 - 0s - loss: 838.0258 - val_loss: 521.2565\n",
      "Epoch 67/1000\n",
      "83/83 - 0s - loss: 830.8093 - val_loss: 519.1891\n",
      "Epoch 68/1000\n",
      "83/83 - 0s - loss: 844.6209 - val_loss: 530.4959\n",
      "Epoch 69/1000\n",
      "83/83 - 0s - loss: 836.2344 - val_loss: 527.3322\n",
      "Epoch 70/1000\n",
      "83/83 - 0s - loss: 842.9238 - val_loss: 528.0196\n",
      "Epoch 71/1000\n",
      "83/83 - 0s - loss: 835.5116 - val_loss: 525.9003\n",
      "Epoch 72/1000\n",
      "83/83 - 0s - loss: 842.1865 - val_loss: 527.2593\n",
      "Epoch 73/1000\n",
      "83/83 - 0s - loss: 834.1921 - val_loss: 524.2484\n",
      "Epoch 74/1000\n",
      "83/83 - 0s - loss: 847.7574 - val_loss: 536.7116\n",
      "Epoch 75/1000\n",
      "83/83 - 0s - loss: 841.6838 - val_loss: 534.6016\n",
      "Epoch 76/1000\n",
      "83/83 - 0s - loss: 842.5631 - val_loss: 532.1171\n",
      "Epoch 77/1000\n",
      "83/83 - 0s - loss: 837.7515 - val_loss: 529.2309\n",
      "Epoch 78/1000\n",
      "83/83 - 0s - loss: 841.6326 - val_loss: 530.6422\n",
      "Epoch 79/1000\n",
      "83/83 - 0s - loss: 836.8549 - val_loss: 527.8625\n",
      "Epoch 80/1000\n",
      "83/83 - 0s - loss: 838.6509 - val_loss: 525.4961\n",
      "Epoch 81/1000\n",
      "83/83 - 0s - loss: 834.5060 - val_loss: 524.0970\n",
      "Epoch 82/1000\n",
      "83/83 - 0s - loss: 835.6174 - val_loss: 521.5510\n",
      "Epoch 83/1000\n",
      "83/83 - 0s - loss: 831.9150 - val_loss: 518.8153\n",
      "Epoch 84/1000\n",
      "83/83 - 0s - loss: 841.5157 - val_loss: 526.4102\n",
      "Epoch 85/1000\n",
      "83/83 - 0s - loss: 839.6136 - val_loss: 526.1615\n",
      "Epoch 86/1000\n",
      "83/83 - 0s - loss: 845.8665 - val_loss: 536.5653\n",
      "Epoch 87/1000\n",
      "83/83 - 0s - loss: 842.3262 - val_loss: 534.1334\n",
      "Epoch 88/1000\n",
      "83/83 - 0s - loss: 842.1951 - val_loss: 531.7807\n",
      "Epoch 89/1000\n",
      "83/83 - 0s - loss: 846.6043 - val_loss: 535.3820\n",
      "Epoch 90/1000\n",
      "83/83 - 0s - loss: 843.4420 - val_loss: 532.9259\n",
      "Epoch 91/1000\n",
      "83/83 - 0s - loss: 846.5212 - val_loss: 539.4594\n",
      "Epoch 92/1000\n",
      "83/83 - 0s - loss: 851.1945 - val_loss: 544.5339\n",
      "Epoch 93/1000\n",
      "83/83 - 0s - loss: 847.5765 - val_loss: 542.7172\n",
      "Epoch 94/1000\n",
      "83/83 - 0s - loss: 847.1215 - val_loss: 540.5858\n",
      "Epoch 95/1000\n",
      "83/83 - 0s - loss: 845.3060 - val_loss: 539.4114\n",
      "Epoch 96/1000\n",
      "83/83 - 0s - loss: 843.6738 - val_loss: 537.2731\n",
      "Epoch 97/1000\n",
      "83/83 - 0s - loss: 841.7875 - val_loss: 535.0875\n",
      "Epoch 98/1000\n",
      "83/83 - 0s - loss: 840.0763 - val_loss: 532.8771\n",
      "Epoch 99/1000\n",
      "83/83 - 0s - loss: 838.5851 - val_loss: 530.6620\n",
      "Epoch 100/1000\n",
      "83/83 - 0s - loss: 837.9086 - val_loss: 529.7246\n",
      "Epoch 101/1000\n",
      "83/83 - 0s - loss: 836.2491 - val_loss: 527.5499\n",
      "Epoch 102/1000\n",
      "83/83 - 0s - loss: 834.7548 - val_loss: 525.3758\n",
      "Epoch 103/1000\n",
      "83/83 - 0s - loss: 833.2659 - val_loss: 523.2004\n",
      "Epoch 104/1000\n",
      "83/83 - 0s - loss: 831.9161 - val_loss: 521.0369\n",
      "Epoch 105/1000\n",
      "83/83 - 0s - loss: 830.4247 - val_loss: 518.8541\n",
      "Epoch 106/1000\n",
      "83/83 - 0s - loss: 829.2637 - val_loss: 516.7061\n",
      "Epoch 107/1000\n",
      "83/83 - 0s - loss: 828.0167 - val_loss: 514.5580\n",
      "Epoch 108/1000\n",
      "83/83 - 0s - loss: 827.1945 - val_loss: 512.4574\n",
      "Epoch 109/1000\n",
      "83/83 - 0s - loss: 825.5272 - val_loss: 510.3268\n",
      "Epoch 110/1000\n",
      "83/83 - 0s - loss: 825.0478 - val_loss: 508.2350\n",
      "Epoch 111/1000\n",
      "83/83 - 0s - loss: 823.3568 - val_loss: 506.1380\n",
      "Epoch 112/1000\n",
      "83/83 - 0s - loss: 833.4080 - val_loss: 517.5370\n",
      "Epoch 113/1000\n",
      "83/83 - 0s - loss: 833.8942 - val_loss: 521.2687\n",
      "Epoch 114/1000\n",
      "83/83 - 0s - loss: 835.5883 - val_loss: 520.4385\n",
      "Epoch 115/1000\n",
      "83/83 - 0s - loss: 848.4321 - val_loss: 541.4077\n",
      "Epoch 116/1000\n",
      "83/83 - 0s - loss: 850.3744 - val_loss: 545.5900\n",
      "Epoch 117/1000\n",
      "83/83 - 0s - loss: 848.0806 - val_loss: 543.9929\n",
      "Epoch 118/1000\n",
      "83/83 - 0s - loss: 847.2014 - val_loss: 542.4377\n",
      "Epoch 119/1000\n",
      "83/83 - 0s - loss: 845.6493 - val_loss: 540.8539\n",
      "Epoch 120/1000\n",
      "83/83 - 0s - loss: 844.4393 - val_loss: 539.2612\n",
      "Epoch 121/1000\n",
      "83/83 - 0s - loss: 843.3499 - val_loss: 537.6541\n",
      "Epoch 122/1000\n",
      "83/83 - 0s - loss: 842.2020 - val_loss: 536.0568\n",
      "Epoch 123/1000\n",
      "83/83 - 0s - loss: 841.0191 - val_loss: 534.4518\n",
      "Epoch 124/1000\n",
      "83/83 - 0s - loss: 839.8661 - val_loss: 532.8533\n",
      "Epoch 125/1000\n",
      "83/83 - 0s - loss: 838.5961 - val_loss: 531.2141\n",
      "Epoch 126/1000\n",
      "83/83 - 0s - loss: 837.7355 - val_loss: 529.5975\n",
      "Epoch 127/1000\n",
      "83/83 - 0s - loss: 836.6830 - val_loss: 527.9987\n",
      "Epoch 128/1000\n",
      "83/83 - 0s - loss: 835.3365 - val_loss: 526.3763\n",
      "Epoch 129/1000\n",
      "83/83 - 0s - loss: 834.3766 - val_loss: 524.7850\n",
      "Epoch 130/1000\n",
      "83/83 - 0s - loss: 833.0275 - val_loss: 523.1263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000\n",
      "83/83 - 0s - loss: 832.9010 - val_loss: 521.5488\n",
      "Epoch 132/1000\n",
      "83/83 - 0s - loss: 831.4188 - val_loss: 519.9424\n",
      "Epoch 133/1000\n",
      "83/83 - 0s - loss: 830.8584 - val_loss: 518.3542\n",
      "Epoch 134/1000\n",
      "83/83 - 0s - loss: 830.1567 - val_loss: 516.7816\n",
      "Epoch 135/1000\n",
      "83/83 - 0s - loss: 834.9062 - val_loss: 521.9191\n",
      "Epoch 136/1000\n",
      "83/83 - 0s - loss: 833.2501 - val_loss: 520.4010\n",
      "Epoch 137/1000\n",
      "83/83 - 0s - loss: 837.0654 - val_loss: 525.5844\n",
      "Epoch 138/1000\n",
      "83/83 - 0s - loss: 837.4067 - val_loss: 524.2156\n",
      "Epoch 139/1000\n",
      "83/83 - 0s - loss: 834.6007 - val_loss: 523.6462\n",
      "Epoch 140/1000\n",
      "83/83 - 0s - loss: 840.7637 - val_loss: 529.2805\n",
      "Epoch 141/1000\n",
      "83/83 - 0s - loss: 836.4487 - val_loss: 527.7961\n",
      "Epoch 142/1000\n",
      "83/83 - 0s - loss: 843.3506 - val_loss: 533.5735\n",
      "Epoch 143/1000\n",
      "83/83 - 0s - loss: 839.8851 - val_loss: 532.1717\n",
      "Epoch 144/1000\n",
      "83/83 - 0s - loss: 845.5856 - val_loss: 538.0355\n",
      "Epoch 145/1000\n",
      "83/83 - 0s - loss: 843.7359 - val_loss: 536.7482\n",
      "Epoch 146/1000\n",
      "83/83 - 0s - loss: 842.8282 - val_loss: 535.4952\n",
      "Epoch 147/1000\n",
      "83/83 - 0s - loss: 841.3382 - val_loss: 534.2124\n",
      "Epoch 148/1000\n",
      "83/83 - 0s - loss: 840.4766 - val_loss: 532.9200\n",
      "Epoch 149/1000\n",
      "83/83 - 0s - loss: 840.2997 - val_loss: 531.6674\n",
      "Epoch 150/1000\n",
      "83/83 - 0s - loss: 840.3524 - val_loss: 530.4065\n",
      "Epoch 151/1000\n",
      "83/83 - 0s - loss: 838.2415 - val_loss: 529.1436\n",
      "Epoch 152/1000\n",
      "83/83 - 0s - loss: 837.3628 - val_loss: 527.8621\n",
      "Epoch 153/1000\n",
      "83/83 - 0s - loss: 836.9167 - val_loss: 526.6002\n",
      "Epoch 154/1000\n",
      "83/83 - 0s - loss: 835.6159 - val_loss: 525.3208\n",
      "Epoch 155/1000\n",
      "83/83 - 0s - loss: 835.5266 - val_loss: 524.0812\n",
      "Epoch 156/1000\n",
      "83/83 - 0s - loss: 838.9498 - val_loss: 530.4509\n",
      "Epoch 157/1000\n",
      "83/83 - 0s - loss: 837.7054 - val_loss: 529.2103\n",
      "Epoch 158/1000\n",
      "83/83 - 0s - loss: 836.9922 - val_loss: 527.9779\n",
      "Epoch 159/1000\n",
      "83/83 - 0s - loss: 836.2326 - val_loss: 526.7400\n",
      "Epoch 160/1000\n",
      "83/83 - 0s - loss: 835.4147 - val_loss: 525.5057\n",
      "Epoch 161/1000\n",
      "83/83 - 0s - loss: 834.4767 - val_loss: 524.2713\n",
      "Epoch 162/1000\n",
      "83/83 - 0s - loss: 833.4646 - val_loss: 523.0282\n",
      "Epoch 163/1000\n",
      "83/83 - 0s - loss: 832.7595 - val_loss: 521.7858\n",
      "Epoch 164/1000\n",
      "83/83 - 0s - loss: 831.8713 - val_loss: 520.5521\n",
      "Epoch 165/1000\n",
      "83/83 - 0s - loss: 830.7041 - val_loss: 519.3038\n",
      "Epoch 166/1000\n",
      "83/83 - 0s - loss: 829.9282 - val_loss: 518.0450\n",
      "Epoch 167/1000\n",
      "83/83 - 0s - loss: 829.2568 - val_loss: 516.8124\n",
      "Epoch 168/1000\n",
      "83/83 - 0s - loss: 828.1759 - val_loss: 515.5651\n",
      "Epoch 169/1000\n",
      "83/83 - 0s - loss: 827.4843 - val_loss: 514.2914\n",
      "Epoch 170/1000\n",
      "83/83 - 0s - loss: 827.2110 - val_loss: 513.0449\n",
      "Epoch 171/1000\n",
      "83/83 - 0s - loss: 825.9796 - val_loss: 511.8188\n",
      "Epoch 172/1000\n",
      "83/83 - 0s - loss: 824.7013 - val_loss: 510.5592\n",
      "Epoch 173/1000\n",
      "83/83 - 0s - loss: 823.8757 - val_loss: 509.2861\n",
      "Epoch 174/1000\n",
      "83/83 - 0s - loss: 824.0558 - val_loss: 508.0660\n",
      "Epoch 175/1000\n",
      "83/83 - 0s - loss: 829.6791 - val_loss: 515.5175\n",
      "Epoch 176/1000\n",
      "83/83 - 0s - loss: 827.5818 - val_loss: 514.2952\n",
      "Epoch 177/1000\n",
      "83/83 - 0s - loss: 829.2726 - val_loss: 513.1807\n",
      "Epoch 178/1000\n",
      "83/83 - 0s - loss: 826.2606 - val_loss: 511.9563\n",
      "Epoch 179/1000\n",
      "83/83 - 0s - loss: 833.4305 - val_loss: 519.5770\n",
      "Epoch 180/1000\n",
      "83/83 - 0s - loss: 830.8423 - val_loss: 518.4318\n",
      "Epoch 181/1000\n",
      "83/83 - 0s - loss: 831.9166 - val_loss: 517.3395\n",
      "Epoch 182/1000\n",
      "83/83 - 0s - loss: 829.4299 - val_loss: 516.2129\n",
      "Epoch 183/1000\n",
      "83/83 - 0s - loss: 828.7756 - val_loss: 515.0490\n",
      "Epoch 184/1000\n",
      "83/83 - 0s - loss: 835.7484 - val_loss: 523.0471\n",
      "Epoch 185/1000\n",
      "83/83 - 0s - loss: 832.9294 - val_loss: 521.9250\n",
      "Epoch 186/1000\n",
      "83/83 - 0s - loss: 832.6342 - val_loss: 520.8418\n",
      "Epoch 187/1000\n",
      "83/83 - 0s - loss: 831.8756 - val_loss: 519.7706\n",
      "Epoch 188/1000\n",
      "83/83 - 0s - loss: 830.9877 - val_loss: 518.6834\n",
      "Epoch 189/1000\n",
      "83/83 - 0s - loss: 837.2460 - val_loss: 526.8282\n",
      "Epoch 190/1000\n",
      "83/83 - 0s - loss: 836.4537 - val_loss: 525.7980\n",
      "Epoch 191/1000\n",
      "83/83 - 0s - loss: 835.9286 - val_loss: 524.7757\n",
      "Epoch 192/1000\n",
      "83/83 - 0s - loss: 835.0846 - val_loss: 523.7648\n",
      "Epoch 193/1000\n",
      "83/83 - 0s - loss: 834.1420 - val_loss: 522.7464\n",
      "Epoch 194/1000\n",
      "83/83 - 0s - loss: 833.7203 - val_loss: 521.7148\n",
      "Epoch 195/1000\n",
      "83/83 - 1s - loss: 840.7178 - val_loss: 530.3745\n",
      "Epoch 196/1000\n",
      "83/83 - 0s - loss: 843.6943 - val_loss: 529.4193\n",
      "Epoch 197/1000\n",
      "83/83 - 0s - loss: 837.6755 - val_loss: 528.4517\n",
      "Epoch 198/1000\n",
      "83/83 - 0s - loss: 836.3163 - val_loss: 527.4494\n",
      "Epoch 199/1000\n",
      "83/83 - 0s - loss: 835.7573 - val_loss: 526.4604\n",
      "Epoch 200/1000\n",
      "83/83 - 0s - loss: 834.0533 - val_loss: 524.0423\n",
      "Epoch 201/1000\n",
      "83/83 - 0s - loss: 842.6376 - val_loss: 534.2889\n",
      "Epoch 202/1000\n",
      "83/83 - 0s - loss: 841.6985 - val_loss: 533.3548\n",
      "Epoch 203/1000\n",
      "83/83 - 0s - loss: 839.3281 - val_loss: 532.3870\n",
      "Epoch 204/1000\n",
      "83/83 - 0s - loss: 838.7028 - val_loss: 531.4248\n",
      "Epoch 205/1000\n",
      "83/83 - 0s - loss: 837.9653 - val_loss: 530.4551\n",
      "Epoch 206/1000\n",
      "83/83 - 0s - loss: 837.3478 - val_loss: 529.4935\n",
      "Epoch 207/1000\n",
      "83/83 - 0s - loss: 836.4905 - val_loss: 528.5173\n",
      "Epoch 208/1000\n",
      "83/83 - 0s - loss: 836.0416 - val_loss: 527.5500\n",
      "Epoch 209/1000\n",
      "83/83 - 0s - loss: 835.2460 - val_loss: 526.5818\n",
      "Epoch 210/1000\n",
      "83/83 - 0s - loss: 834.6268 - val_loss: 525.6115\n",
      "Epoch 211/1000\n",
      "83/83 - 0s - loss: 833.9564 - val_loss: 524.6359\n",
      "Epoch 212/1000\n",
      "83/83 - 0s - loss: 833.4207 - val_loss: 523.6766\n",
      "Epoch 213/1000\n",
      "83/83 - 0s - loss: 832.5896 - val_loss: 522.7046\n",
      "Epoch 214/1000\n",
      "83/83 - 0s - loss: 831.8344 - val_loss: 521.7211\n",
      "Epoch 215/1000\n",
      "83/83 - 0s - loss: 831.6857 - val_loss: 520.7894\n",
      "Epoch 216/1000\n",
      "83/83 - 0s - loss: 830.2369 - val_loss: 519.7764\n",
      "Epoch 217/1000\n",
      "83/83 - 0s - loss: 830.9897 - val_loss: 518.8473\n",
      "Epoch 218/1000\n",
      "83/83 - 0s - loss: 829.3426 - val_loss: 517.8672\n",
      "Epoch 219/1000\n",
      "83/83 - 0s - loss: 829.0410 - val_loss: 516.9048\n",
      "Epoch 220/1000\n",
      "83/83 - 0s - loss: 828.5593 - val_loss: 515.9489\n",
      "Epoch 221/1000\n",
      "83/83 - 0s - loss: 828.1380 - val_loss: 514.9972\n",
      "Epoch 222/1000\n",
      "83/83 - 0s - loss: 830.3234 - val_loss: 514.0723\n",
      "Epoch 223/1000\n",
      "83/83 - 0s - loss: 827.9844 - val_loss: 513.1432\n",
      "Epoch 224/1000\n",
      "83/83 - 0s - loss: 842.6097 - val_loss: 534.2264\n",
      "Epoch 225/1000\n",
      "83/83 - 0s - loss: 841.1605 - val_loss: 533.4510\n",
      "Epoch 226/1000\n",
      "83/83 - 0s - loss: 839.1989 - val_loss: 532.5364\n",
      "Epoch 227/1000\n",
      "83/83 - 0s - loss: 838.8602 - val_loss: 531.6745\n",
      "Epoch 228/1000\n",
      "83/83 - 0s - loss: 838.0663 - val_loss: 530.8007\n",
      "Epoch 229/1000\n",
      "83/83 - 0s - loss: 837.5747 - val_loss: 529.9194\n",
      "Epoch 230/1000\n",
      "83/83 - 0s - loss: 837.2529 - val_loss: 529.0983\n",
      "Epoch 231/1000\n",
      "83/83 - 0s - loss: 835.7578 - val_loss: 528.1680\n",
      "Epoch 232/1000\n",
      "83/83 - 0s - loss: 836.9479 - val_loss: 527.3304\n",
      "Epoch 233/1000\n",
      "83/83 - 0s - loss: 836.1368 - val_loss: 526.4683\n",
      "Epoch 234/1000\n",
      "83/83 - 0s - loss: 835.3560 - val_loss: 525.6057\n",
      "Epoch 235/1000\n",
      "83/83 - 0s - loss: 835.0082 - val_loss: 524.7640\n",
      "Epoch 236/1000\n",
      "83/83 - 0s - loss: 834.0485 - val_loss: 523.9092\n",
      "Epoch 237/1000\n",
      "83/83 - 0s - loss: 833.5025 - val_loss: 523.0568\n",
      "Epoch 238/1000\n",
      "83/83 - 0s - loss: 832.4100 - val_loss: 522.1927\n",
      "Epoch 239/1000\n",
      "83/83 - 0s - loss: 831.8365 - val_loss: 521.3273\n",
      "Epoch 240/1000\n",
      "83/83 - 0s - loss: 831.2909 - val_loss: 520.4619\n",
      "Epoch 241/1000\n",
      "83/83 - 0s - loss: 830.9644 - val_loss: 519.5988\n",
      "Epoch 242/1000\n",
      "83/83 - 0s - loss: 830.1073 - val_loss: 518.7330\n",
      "Epoch 243/1000\n",
      "83/83 - 0s - loss: 829.7827 - val_loss: 517.8702\n",
      "Epoch 244/1000\n",
      "83/83 - 0s - loss: 829.7565 - val_loss: 517.0172\n",
      "Epoch 245/1000\n",
      "83/83 - 0s - loss: 837.6738 - val_loss: 528.2200\n",
      "Epoch 246/1000\n",
      "83/83 - 0s - loss: 836.2609 - val_loss: 527.4178\n",
      "Epoch 247/1000\n",
      "83/83 - 0s - loss: 835.4653 - val_loss: 526.6183\n",
      "Epoch 248/1000\n",
      "83/83 - 0s - loss: 834.3523 - val_loss: 525.7650\n",
      "Epoch 249/1000\n",
      "83/83 - 0s - loss: 835.1147 - val_loss: 524.9728\n",
      "Epoch 250/1000\n",
      "83/83 - 0s - loss: 833.9927 - val_loss: 524.1603\n",
      "Epoch 251/1000\n",
      "83/83 - 0s - loss: 833.1055 - val_loss: 523.3398\n",
      "Epoch 252/1000\n",
      "83/83 - 0s - loss: 832.6269 - val_loss: 522.5245\n",
      "Epoch 253/1000\n",
      "83/83 - 0s - loss: 831.9680 - val_loss: 521.7035\n",
      "Epoch 254/1000\n",
      "83/83 - 0s - loss: 831.4893 - val_loss: 520.8783\n",
      "Epoch 255/1000\n",
      "83/83 - 0s - loss: 831.6396 - val_loss: 520.0802\n",
      "Epoch 256/1000\n",
      "83/83 - 0s - loss: 830.6303 - val_loss: 519.2682\n",
      "Epoch 257/1000\n",
      "83/83 - 0s - loss: 830.1821 - val_loss: 518.4572\n",
      "Epoch 258/1000\n",
      "83/83 - 0s - loss: 829.7062 - val_loss: 517.6452\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 0s - loss: 829.3647 - val_loss: 516.8484\n",
      "Epoch 260/1000\n",
      "83/83 - 0s - loss: 828.5413 - val_loss: 516.0260\n",
      "Epoch 261/1000\n",
      "83/83 - 0s - loss: 828.4287 - val_loss: 515.2278\n",
      "Epoch 262/1000\n",
      "83/83 - 0s - loss: 828.2147 - val_loss: 514.4391\n",
      "Epoch 263/1000\n",
      "83/83 - 0s - loss: 827.5975 - val_loss: 513.6293\n",
      "Epoch 264/1000\n",
      "83/83 - 0s - loss: 846.2200 - val_loss: 538.9547\n",
      "Epoch 265/1000\n",
      "83/83 - 0s - loss: 844.0356 - val_loss: 538.2414\n",
      "Epoch 266/1000\n",
      "83/83 - 0s - loss: 842.8581 - val_loss: 537.5266\n",
      "Epoch 267/1000\n",
      "83/83 - 0s - loss: 842.4091 - val_loss: 536.8090\n",
      "Epoch 268/1000\n",
      "83/83 - 0s - loss: 841.8371 - val_loss: 536.0908\n",
      "Epoch 269/1000\n",
      "83/83 - 0s - loss: 841.3757 - val_loss: 535.3713\n",
      "Epoch 270/1000\n",
      "83/83 - 0s - loss: 840.9247 - val_loss: 534.6564\n",
      "Epoch 271/1000\n",
      "83/83 - 0s - loss: 840.3568 - val_loss: 533.9373\n",
      "Epoch 272/1000\n",
      "83/83 - 0s - loss: 839.8291 - val_loss: 533.2196\n",
      "Epoch 273/1000\n",
      "83/83 - 0s - loss: 839.2385 - val_loss: 532.4960\n",
      "Epoch 274/1000\n",
      "83/83 - 0s - loss: 838.7423 - val_loss: 531.7684\n",
      "Epoch 275/1000\n",
      "83/83 - 0s - loss: 838.5531 - val_loss: 531.0568\n",
      "Epoch 276/1000\n",
      "83/83 - 0s - loss: 837.6904 - val_loss: 530.3337\n",
      "Epoch 277/1000\n",
      "83/83 - 0s - loss: 837.3379 - val_loss: 529.6081\n",
      "Epoch 278/1000\n",
      "83/83 - 0s - loss: 836.9793 - val_loss: 528.8909\n",
      "Epoch 279/1000\n",
      "83/83 - 0s - loss: 836.4189 - val_loss: 528.1700\n",
      "Epoch 280/1000\n",
      "83/83 - 0s - loss: 836.0835 - val_loss: 527.4572\n",
      "Epoch 281/1000\n",
      "83/83 - 0s - loss: 835.3424 - val_loss: 526.7373\n",
      "Epoch 282/1000\n",
      "83/83 - 0s - loss: 834.7664 - val_loss: 526.0063\n",
      "Epoch 283/1000\n",
      "83/83 - 0s - loss: 834.7684 - val_loss: 525.2956\n",
      "Epoch 284/1000\n",
      "83/83 - 0s - loss: 834.0157 - val_loss: 524.5804\n",
      "Epoch 285/1000\n",
      "83/83 - 0s - loss: 833.4316 - val_loss: 523.8602\n",
      "Epoch 286/1000\n",
      "83/83 - 0s - loss: 832.8659 - val_loss: 523.1331\n",
      "Epoch 287/1000\n",
      "83/83 - 0s - loss: 832.8040 - val_loss: 522.4244\n",
      "Epoch 288/1000\n",
      "83/83 - 0s - loss: 831.9796 - val_loss: 521.7023\n",
      "Epoch 289/1000\n",
      "83/83 - 0s - loss: 831.5472 - val_loss: 520.9837\n",
      "Epoch 290/1000\n",
      "83/83 - 0s - loss: 831.1668 - val_loss: 520.2712\n",
      "Epoch 291/1000\n",
      "83/83 - 0s - loss: 830.5875 - val_loss: 519.5482\n",
      "Epoch 292/1000\n",
      "83/83 - 0s - loss: 830.6362 - val_loss: 518.8394\n",
      "Epoch 293/1000\n",
      "83/83 - 0s - loss: 830.1907 - val_loss: 518.1295\n",
      "Epoch 294/1000\n",
      "83/83 - 0s - loss: 829.9838 - val_loss: 517.4211\n",
      "Epoch 295/1000\n",
      "83/83 - 0s - loss: 830.9706 - val_loss: 516.7290\n",
      "Epoch 296/1000\n",
      "83/83 - 0s - loss: 828.5488 - val_loss: 516.0120\n",
      "Epoch 297/1000\n",
      "83/83 - 0s - loss: 829.2388 - val_loss: 515.3085\n",
      "Epoch 298/1000\n",
      "83/83 - 0s - loss: 831.1812 - val_loss: 514.6320\n",
      "Epoch 299/1000\n",
      "83/83 - 0s - loss: 829.2466 - val_loss: 513.9370\n",
      "Epoch 300/1000\n",
      "83/83 - 0s - loss: 839.1323 - val_loss: 528.0628\n",
      "Epoch 301/1000\n",
      "83/83 - 0s - loss: 859.8663 - val_loss: 557.3911\n",
      "Epoch 302/1000\n",
      "83/83 - 0s - loss: 855.5297 - val_loss: 555.2418\n",
      "Epoch 303/1000\n",
      "83/83 - 0s - loss: 855.2348 - val_loss: 554.4705\n",
      "Epoch 304/1000\n",
      "83/83 - 0s - loss: 853.8725 - val_loss: 553.6498\n",
      "Epoch 305/1000\n",
      "83/83 - 0s - loss: 853.9612 - val_loss: 552.9510\n",
      "Epoch 306/1000\n",
      "83/83 - 0s - loss: 852.7357 - val_loss: 552.1719\n",
      "Epoch 307/1000\n",
      "83/83 - 0s - loss: 852.4468 - val_loss: 551.4620\n",
      "Epoch 308/1000\n",
      "83/83 - 0s - loss: 851.6575 - val_loss: 550.7101\n",
      "Epoch 309/1000\n",
      "83/83 - 0s - loss: 851.6954 - val_loss: 550.0236\n",
      "Epoch 310/1000\n",
      "83/83 - 0s - loss: 850.7840 - val_loss: 549.3027\n",
      "Epoch 311/1000\n",
      "83/83 - 0s - loss: 850.4763 - val_loss: 548.6097\n",
      "Epoch 312/1000\n",
      "83/83 - 0s - loss: 849.8173 - val_loss: 547.9012\n",
      "Epoch 313/1000\n",
      "83/83 - 0s - loss: 849.6606 - val_loss: 547.2142\n",
      "Epoch 314/1000\n",
      "83/83 - 0s - loss: 849.1686 - val_loss: 546.5339\n",
      "Epoch 315/1000\n",
      "83/83 - 0s - loss: 848.4833 - val_loss: 545.8396\n",
      "Epoch 316/1000\n",
      "83/83 - 0s - loss: 848.1494 - val_loss: 545.1569\n",
      "Epoch 317/1000\n",
      "83/83 - 0s - loss: 847.6549 - val_loss: 544.4782\n",
      "Epoch 318/1000\n",
      "83/83 - 0s - loss: 847.0685 - val_loss: 543.7892\n",
      "Epoch 319/1000\n",
      "83/83 - 0s - loss: 846.6204 - val_loss: 543.1058\n",
      "Epoch 320/1000\n",
      "83/83 - 0s - loss: 846.2313 - val_loss: 542.4264\n",
      "Epoch 321/1000\n",
      "83/83 - 0s - loss: 845.7298 - val_loss: 541.7512\n",
      "Epoch 322/1000\n",
      "83/83 - 0s - loss: 845.2286 - val_loss: 541.0734\n",
      "Epoch 323/1000\n",
      "83/83 - 0s - loss: 844.7010 - val_loss: 540.3917\n",
      "Epoch 324/1000\n",
      "83/83 - 0s - loss: 844.2728 - val_loss: 539.7126\n",
      "Epoch 325/1000\n",
      "83/83 - 0s - loss: 843.7725 - val_loss: 539.0295\n",
      "Epoch 326/1000\n",
      "83/83 - 0s - loss: 843.6569 - val_loss: 538.3654\n",
      "Epoch 327/1000\n",
      "83/83 - 0s - loss: 843.0315 - val_loss: 537.6942\n",
      "Epoch 328/1000\n",
      "83/83 - 0s - loss: 842.3505 - val_loss: 537.0097\n",
      "Epoch 329/1000\n",
      "83/83 - 0s - loss: 842.3611 - val_loss: 536.3417\n",
      "Epoch 330/1000\n",
      "83/83 - 0s - loss: 841.7935 - val_loss: 535.6750\n",
      "Epoch 331/1000\n",
      "83/83 - 0s - loss: 841.3627 - val_loss: 535.0062\n",
      "Epoch 332/1000\n",
      "83/83 - 0s - loss: 841.0397 - val_loss: 534.3476\n",
      "Epoch 333/1000\n",
      "83/83 - 0s - loss: 840.1467 - val_loss: 533.6698\n",
      "Epoch 334/1000\n",
      "83/83 - 0s - loss: 840.0213 - val_loss: 533.0020\n",
      "Epoch 335/1000\n",
      "83/83 - 0s - loss: 839.6423 - val_loss: 532.3373\n",
      "Epoch 336/1000\n",
      "83/83 - 0s - loss: 839.2173 - val_loss: 531.6753\n",
      "Epoch 337/1000\n",
      "83/83 - 0s - loss: 839.2488 - val_loss: 531.0010\n",
      "Epoch 338/1000\n",
      "83/83 - 0s - loss: 850.7916 - val_loss: 546.9684\n",
      "Epoch 339/1000\n",
      "83/83 - 0s - loss: 848.9993 - val_loss: 546.3506\n",
      "Epoch 340/1000\n",
      "83/83 - 0s - loss: 848.6701 - val_loss: 545.7267\n",
      "Epoch 341/1000\n",
      "83/83 - 0s - loss: 848.5907 - val_loss: 545.1240\n",
      "Epoch 342/1000\n",
      "83/83 - 0s - loss: 847.7604 - val_loss: 544.4987\n",
      "Epoch 343/1000\n",
      "83/83 - 0s - loss: 847.6640 - val_loss: 543.8993\n",
      "Epoch 344/1000\n",
      "83/83 - 0s - loss: 846.9107 - val_loss: 543.2801\n",
      "Epoch 345/1000\n",
      "83/83 - 0s - loss: 846.4631 - val_loss: 542.6734\n",
      "Epoch 346/1000\n",
      "83/83 - 0s - loss: 845.7443 - val_loss: 542.0392\n",
      "Epoch 347/1000\n",
      "83/83 - 0s - loss: 845.6043 - val_loss: 541.4188\n",
      "Epoch 348/1000\n",
      "83/83 - 0s - loss: 845.3875 - val_loss: 540.8116\n",
      "Epoch 349/1000\n",
      "83/83 - 0s - loss: 844.7016 - val_loss: 540.1924\n",
      "Epoch 350/1000\n",
      "83/83 - 0s - loss: 844.3071 - val_loss: 539.5724\n",
      "Epoch 351/1000\n",
      "83/83 - 0s - loss: 843.9857 - val_loss: 538.9604\n",
      "Epoch 352/1000\n",
      "83/83 - 0s - loss: 843.5362 - val_loss: 538.3456\n",
      "Epoch 353/1000\n",
      "83/83 - 0s - loss: 843.1172 - val_loss: 537.7311\n",
      "Epoch 354/1000\n",
      "83/83 - 0s - loss: 842.6651 - val_loss: 537.1100\n",
      "Epoch 355/1000\n",
      "83/83 - 0s - loss: 842.4515 - val_loss: 536.5062\n",
      "Epoch 356/1000\n",
      "83/83 - 0s - loss: 841.5815 - val_loss: 535.8824\n",
      "Epoch 357/1000\n",
      "83/83 - 0s - loss: 841.2160 - val_loss: 535.2646\n",
      "Epoch 358/1000\n",
      "83/83 - 0s - loss: 840.7273 - val_loss: 534.6411\n",
      "Epoch 359/1000\n",
      "83/83 - 0s - loss: 840.3102 - val_loss: 534.0157\n",
      "Epoch 360/1000\n",
      "83/83 - 0s - loss: 840.1510 - val_loss: 533.4076\n",
      "Epoch 361/1000\n",
      "83/83 - 0s - loss: 839.2501 - val_loss: 532.7756\n",
      "Epoch 362/1000\n",
      "83/83 - 0s - loss: 839.2082 - val_loss: 532.1652\n",
      "Epoch 363/1000\n",
      "83/83 - 0s - loss: 838.3768 - val_loss: 531.5316\n",
      "Epoch 364/1000\n",
      "83/83 - 0s - loss: 838.4298 - val_loss: 530.9181\n",
      "Epoch 365/1000\n",
      "83/83 - 0s - loss: 837.7295 - val_loss: 530.3010\n",
      "Epoch 366/1000\n",
      "83/83 - 0s - loss: 837.2214 - val_loss: 529.6728\n",
      "Epoch 367/1000\n",
      "83/83 - 0s - loss: 836.9769 - val_loss: 529.0519\n",
      "Epoch 368/1000\n",
      "83/83 - 0s - loss: 836.6569 - val_loss: 528.4347\n",
      "Epoch 369/1000\n",
      "83/83 - 0s - loss: 836.2548 - val_loss: 527.8240\n",
      "Epoch 370/1000\n",
      "83/83 - 0s - loss: 835.5505 - val_loss: 527.2000\n",
      "Epoch 371/1000\n",
      "83/83 - 0s - loss: 835.0065 - val_loss: 526.5702\n",
      "Epoch 372/1000\n",
      "83/83 - 0s - loss: 835.0356 - val_loss: 525.9557\n",
      "Epoch 373/1000\n",
      "83/83 - 0s - loss: 834.6403 - val_loss: 525.3432\n",
      "Epoch 374/1000\n",
      "83/83 - 0s - loss: 834.1061 - val_loss: 524.7280\n",
      "Epoch 375/1000\n",
      "83/83 - 0s - loss: 833.4980 - val_loss: 524.0987\n",
      "Epoch 376/1000\n",
      "83/83 - 0s - loss: 833.9412 - val_loss: 523.5078\n",
      "Epoch 377/1000\n",
      "83/83 - 0s - loss: 832.5790 - val_loss: 522.8828\n",
      "Epoch 378/1000\n",
      "83/83 - 0s - loss: 832.1034 - val_loss: 522.2553\n",
      "Epoch 379/1000\n",
      "83/83 - 0s - loss: 832.0646 - val_loss: 521.6406\n",
      "Epoch 380/1000\n",
      "83/83 - 0s - loss: 831.7574 - val_loss: 521.0341\n",
      "Epoch 381/1000\n",
      "83/83 - 0s - loss: 830.8934 - val_loss: 520.4047\n",
      "Epoch 382/1000\n",
      "83/83 - 0s - loss: 830.8926 - val_loss: 519.7944\n",
      "Epoch 383/1000\n",
      "83/83 - 0s - loss: 830.4572 - val_loss: 519.1847\n",
      "Epoch 384/1000\n",
      "83/83 - 0s - loss: 829.8860 - val_loss: 518.5604\n",
      "Epoch 385/1000\n",
      "83/83 - 0s - loss: 829.8344 - val_loss: 517.9505\n",
      "Epoch 386/1000\n",
      "83/83 - 0s - loss: 829.4702 - val_loss: 517.3405\n",
      "Epoch 387/1000\n",
      "83/83 - 0s - loss: 829.2152 - val_loss: 516.7256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "83/83 - 0s - loss: 842.9722 - val_loss: 535.3164\n",
      "Epoch 389/1000\n",
      "83/83 - 0s - loss: 840.8082 - val_loss: 534.7399\n",
      "Epoch 390/1000\n",
      "83/83 - 0s - loss: 840.6465 - val_loss: 534.1791\n",
      "Epoch 391/1000\n",
      "83/83 - 0s - loss: 840.0626 - val_loss: 533.6068\n",
      "Epoch 392/1000\n",
      "83/83 - 0s - loss: 839.8794 - val_loss: 533.0395\n",
      "Epoch 393/1000\n",
      "83/83 - 0s - loss: 839.6299 - val_loss: 532.4830\n",
      "Epoch 394/1000\n",
      "83/83 - 0s - loss: 838.9134 - val_loss: 531.9138\n",
      "Epoch 395/1000\n",
      "83/83 - 0s - loss: 838.5547 - val_loss: 531.3440\n",
      "Epoch 396/1000\n",
      "83/83 - 0s - loss: 838.2267 - val_loss: 530.7764\n",
      "Epoch 397/1000\n",
      "83/83 - 0s - loss: 837.9902 - val_loss: 530.2233\n",
      "Epoch 398/1000\n",
      "83/83 - 0s - loss: 837.1389 - val_loss: 529.6467\n",
      "Epoch 399/1000\n",
      "83/83 - 0s - loss: 836.9566 - val_loss: 529.0795\n",
      "Epoch 400/1000\n",
      "83/83 - 0s - loss: 836.4996 - val_loss: 528.5036\n",
      "Epoch 401/1000\n",
      "83/83 - 0s - loss: 836.5693 - val_loss: 527.9511\n",
      "Epoch 402/1000\n",
      "83/83 - 0s - loss: 835.6036 - val_loss: 527.3801\n",
      "Epoch 403/1000\n",
      "83/83 - 0s - loss: 835.2570 - val_loss: 526.8081\n",
      "Epoch 404/1000\n",
      "83/83 - 0s - loss: 834.8514 - val_loss: 526.2359\n",
      "Epoch 405/1000\n",
      "83/83 - 0s - loss: 834.5038 - val_loss: 525.6652\n",
      "Epoch 406/1000\n",
      "83/83 - 0s - loss: 834.1527 - val_loss: 525.1003\n",
      "Epoch 407/1000\n",
      "83/83 - 0s - loss: 833.5990 - val_loss: 524.5270\n",
      "Epoch 408/1000\n",
      "83/83 - 0s - loss: 833.2549 - val_loss: 523.9524\n",
      "Epoch 409/1000\n",
      "83/83 - 0s - loss: 832.9676 - val_loss: 523.3815\n",
      "Epoch 410/1000\n",
      "83/83 - 0s - loss: 832.6434 - val_loss: 522.8156\n",
      "Epoch 411/1000\n",
      "83/83 - 0s - loss: 832.0897 - val_loss: 522.2405\n",
      "Epoch 412/1000\n",
      "83/83 - 0s - loss: 832.0261 - val_loss: 521.6771\n",
      "Epoch 413/1000\n",
      "83/83 - 0s - loss: 831.4787 - val_loss: 521.1113\n",
      "Epoch 414/1000\n",
      "83/83 - 0s - loss: 830.8641 - val_loss: 520.5341\n",
      "Epoch 415/1000\n",
      "83/83 - 0s - loss: 830.8580 - val_loss: 519.9698\n",
      "Epoch 416/1000\n",
      "83/83 - 0s - loss: 830.2579 - val_loss: 519.3982\n",
      "Epoch 417/1000\n",
      "83/83 - 0s - loss: 830.1712 - val_loss: 518.8372\n",
      "Epoch 418/1000\n",
      "83/83 - 0s - loss: 829.6151 - val_loss: 518.2725\n",
      "Epoch 419/1000\n",
      "83/83 - 0s - loss: 829.0306 - val_loss: 517.6967\n",
      "Epoch 420/1000\n",
      "83/83 - 0s - loss: 829.0729 - val_loss: 517.1357\n",
      "Epoch 421/1000\n",
      "83/83 - 0s - loss: 828.4725 - val_loss: 516.5675\n",
      "Epoch 422/1000\n",
      "83/83 - 0s - loss: 828.5316 - val_loss: 516.0083\n",
      "Epoch 423/1000\n",
      "83/83 - 0s - loss: 828.1182 - val_loss: 515.4476\n",
      "Epoch 424/1000\n",
      "83/83 - 0s - loss: 830.6100 - val_loss: 514.9020\n",
      "Epoch 425/1000\n",
      "83/83 - 0s - loss: 827.0643 - val_loss: 514.3355\n",
      "Epoch 426/1000\n",
      "83/83 - 0s - loss: 827.1835 - val_loss: 513.7751\n",
      "Epoch 427/1000\n",
      "83/83 - 0s - loss: 827.3882 - val_loss: 513.2190\n",
      "Epoch 428/1000\n",
      "83/83 - 0s - loss: 828.1240 - val_loss: 512.6635\n",
      "Epoch 429/1000\n",
      "83/83 - 0s - loss: 829.2111 - val_loss: 512.1639\n",
      "Epoch 430/1000\n",
      "83/83 - 0s - loss: 832.9860 - val_loss: 518.4044\n",
      "Epoch 431/1000\n",
      "83/83 - 0s - loss: 832.1549 - val_loss: 517.9489\n",
      "Epoch 432/1000\n",
      "83/83 - 0s - loss: 838.6404 - val_loss: 528.9994\n",
      "Epoch 433/1000\n",
      "83/83 - 0s - loss: 838.9859 - val_loss: 528.5509\n",
      "Epoch 434/1000\n",
      "83/83 - 0s - loss: 840.0417 - val_loss: 532.0575\n",
      "Epoch 435/1000\n",
      "83/83 - 0s - loss: 839.6589 - val_loss: 531.2426\n",
      "Epoch 436/1000\n",
      "83/83 - 0s - loss: 837.6572 - val_loss: 530.2079\n",
      "Epoch 437/1000\n",
      "83/83 - 0s - loss: 837.8765 - val_loss: 529.3317\n",
      "Epoch 438/1000\n",
      "83/83 - 0s - loss: 836.7448 - val_loss: 528.4218\n",
      "Epoch 439/1000\n",
      "83/83 - 0s - loss: 836.7851 - val_loss: 527.6027\n",
      "Epoch 440/1000\n",
      "83/83 - 0s - loss: 835.8110 - val_loss: 526.7852\n",
      "Epoch 441/1000\n",
      "83/83 - 0s - loss: 835.0800 - val_loss: 525.9600\n",
      "Epoch 442/1000\n",
      "83/83 - 0s - loss: 834.9394 - val_loss: 525.1787\n",
      "Epoch 443/1000\n",
      "83/83 - 0s - loss: 833.9189 - val_loss: 524.3859\n",
      "Epoch 444/1000\n",
      "83/83 - 0s - loss: 833.4854 - val_loss: 523.6183\n",
      "Epoch 445/1000\n",
      "83/83 - 0s - loss: 830.2617 - val_loss: 519.3861\n",
      "Epoch 446/1000\n",
      "83/83 - 0s - loss: 830.0563 - val_loss: 518.6265\n",
      "Epoch 447/1000\n",
      "83/83 - 0s - loss: 829.2365 - val_loss: 517.8615\n",
      "Epoch 448/1000\n",
      "83/83 - 0s - loss: 828.7256 - val_loss: 517.1038\n",
      "Epoch 449/1000\n",
      "83/83 - 0s - loss: 828.1957 - val_loss: 516.3421\n",
      "Epoch 450/1000\n",
      "83/83 - 0s - loss: 827.7661 - val_loss: 515.5977\n",
      "Epoch 451/1000\n",
      "83/83 - 0s - loss: 827.0904 - val_loss: 514.8419\n",
      "Epoch 452/1000\n",
      "83/83 - 0s - loss: 826.8662 - val_loss: 514.0992\n",
      "Epoch 453/1000\n",
      "83/83 - 0s - loss: 825.9838 - val_loss: 513.3436\n",
      "Epoch 454/1000\n",
      "83/83 - 0s - loss: 826.3159 - val_loss: 512.6227\n",
      "Epoch 455/1000\n",
      "83/83 - 0s - loss: 825.5135 - val_loss: 511.8945\n",
      "Epoch 456/1000\n",
      "83/83 - 0s - loss: 825.0646 - val_loss: 511.1646\n",
      "Epoch 457/1000\n",
      "83/83 - 0s - loss: 824.9810 - val_loss: 510.4505\n",
      "Epoch 458/1000\n",
      "83/83 - 0s - loss: 824.6644 - val_loss: 509.7341\n",
      "Epoch 459/1000\n",
      "83/83 - 0s - loss: 824.1187 - val_loss: 509.0055\n",
      "Epoch 460/1000\n",
      "83/83 - 0s - loss: 824.2150 - val_loss: 508.3226\n",
      "Epoch 461/1000\n",
      "83/83 - 0s - loss: 823.0516 - val_loss: 507.6037\n",
      "Epoch 462/1000\n",
      "83/83 - 0s - loss: 822.1703 - val_loss: 506.8869\n",
      "Epoch 463/1000\n",
      "83/83 - 0s - loss: 822.5137 - val_loss: 506.1741\n",
      "Epoch 464/1000\n",
      "83/83 - 0s - loss: 838.9323 - val_loss: 528.5614\n",
      "Epoch 465/1000\n",
      "83/83 - 0s - loss: 836.0150 - val_loss: 527.8715\n",
      "Epoch 466/1000\n",
      "83/83 - 0s - loss: 835.7804 - val_loss: 527.2255\n",
      "Epoch 467/1000\n",
      "83/83 - 0s - loss: 834.5597 - val_loss: 526.2717\n",
      "Epoch 468/1000\n",
      "83/83 - 0s - loss: 834.6411 - val_loss: 525.4929\n",
      "Epoch 469/1000\n",
      "83/83 - 0s - loss: 833.3521 - val_loss: 524.6395\n",
      "Epoch 470/1000\n",
      "83/83 - 0s - loss: 833.9074 - val_loss: 523.9122\n",
      "Epoch 471/1000\n",
      "83/83 - 0s - loss: 832.3224 - val_loss: 523.1105\n",
      "Epoch 472/1000\n",
      "83/83 - 0s - loss: 832.5674 - val_loss: 522.3824\n",
      "Epoch 473/1000\n",
      "83/83 - 0s - loss: 831.4005 - val_loss: 521.6090\n",
      "Epoch 474/1000\n",
      "83/83 - 0s - loss: 831.2632 - val_loss: 520.8748\n",
      "Epoch 475/1000\n",
      "83/83 - 0s - loss: 830.5414 - val_loss: 520.1193\n",
      "Epoch 476/1000\n",
      "83/83 - 0s - loss: 830.3141 - val_loss: 519.3881\n",
      "Epoch 477/1000\n",
      "83/83 - 0s - loss: 829.7847 - val_loss: 518.6555\n",
      "Epoch 478/1000\n",
      "83/83 - 0s - loss: 829.1041 - val_loss: 517.9129\n",
      "Epoch 479/1000\n",
      "83/83 - 0s - loss: 828.7878 - val_loss: 517.1867\n",
      "Epoch 480/1000\n",
      "83/83 - 0s - loss: 828.2407 - val_loss: 516.4613\n",
      "Epoch 481/1000\n",
      "83/83 - 0s - loss: 827.5550 - val_loss: 515.7153\n",
      "Epoch 482/1000\n",
      "83/83 - 0s - loss: 827.7066 - val_loss: 515.0065\n",
      "Epoch 483/1000\n",
      "83/83 - 0s - loss: 826.8378 - val_loss: 514.2736\n",
      "Epoch 484/1000\n",
      "83/83 - 0s - loss: 827.3242 - val_loss: 513.5718\n",
      "Epoch 485/1000\n",
      "83/83 - 0s - loss: 826.5793 - val_loss: 512.8608\n",
      "Epoch 486/1000\n",
      "83/83 - 0s - loss: 843.7152 - val_loss: 536.1234\n",
      "Epoch 487/1000\n",
      "83/83 - 0s - loss: 841.4022 - val_loss: 535.4491\n",
      "Epoch 488/1000\n",
      "83/83 - 0s - loss: 840.7834 - val_loss: 534.7699\n",
      "Epoch 489/1000\n",
      "83/83 - 0s - loss: 840.2366 - val_loss: 534.0995\n",
      "Epoch 490/1000\n",
      "83/83 - 0s - loss: 839.5066 - val_loss: 533.4062\n",
      "Epoch 491/1000\n",
      "83/83 - 0s - loss: 839.4094 - val_loss: 532.7454\n",
      "Epoch 492/1000\n",
      "83/83 - 0s - loss: 838.5410 - val_loss: 532.0472\n",
      "Epoch 493/1000\n",
      "83/83 - 0s - loss: 838.6720 - val_loss: 531.3949\n",
      "Epoch 494/1000\n",
      "83/83 - 0s - loss: 837.6946 - val_loss: 530.7025\n",
      "Epoch 495/1000\n",
      "83/83 - 0s - loss: 837.6738 - val_loss: 530.0453\n",
      "Epoch 496/1000\n",
      "83/83 - 0s - loss: 836.6702 - val_loss: 529.3544\n",
      "Epoch 497/1000\n",
      "83/83 - 0s - loss: 836.6702 - val_loss: 528.6914\n",
      "Epoch 498/1000\n",
      "83/83 - 0s - loss: 836.0744 - val_loss: 528.0205\n",
      "Epoch 499/1000\n",
      "83/83 - 0s - loss: 835.3484 - val_loss: 527.3336\n",
      "Epoch 500/1000\n",
      "83/83 - 0s - loss: 835.4019 - val_loss: 526.6736\n",
      "Epoch 501/1000\n",
      "83/83 - 0s - loss: 834.7257 - val_loss: 526.0046\n",
      "Epoch 502/1000\n",
      "83/83 - 0s - loss: 834.0671 - val_loss: 525.3253\n",
      "Epoch 503/1000\n",
      "83/83 - 0s - loss: 833.6246 - val_loss: 524.6490\n",
      "Epoch 504/1000\n",
      "83/83 - 0s - loss: 833.3615 - val_loss: 523.9804\n",
      "Epoch 505/1000\n",
      "83/83 - 0s - loss: 833.0206 - val_loss: 523.3203\n",
      "Epoch 506/1000\n",
      "83/83 - 0s - loss: 832.2594 - val_loss: 522.6391\n",
      "Epoch 507/1000\n",
      "83/83 - 0s - loss: 832.1354 - val_loss: 521.9709\n",
      "Epoch 508/1000\n",
      "83/83 - 0s - loss: 831.7415 - val_loss: 521.3073\n",
      "Epoch 509/1000\n",
      "83/83 - 0s - loss: 831.2794 - val_loss: 520.6439\n",
      "Epoch 510/1000\n",
      "83/83 - 0s - loss: 830.8663 - val_loss: 519.9888\n",
      "Epoch 511/1000\n",
      "83/83 - 0s - loss: 830.0772 - val_loss: 519.3123\n",
      "Epoch 512/1000\n",
      "83/83 - 0s - loss: 829.6547 - val_loss: 518.6413\n",
      "Epoch 513/1000\n",
      "83/83 - 0s - loss: 829.4948 - val_loss: 517.9844\n",
      "Epoch 514/1000\n",
      "83/83 - 0s - loss: 828.8125 - val_loss: 517.3157\n",
      "Epoch 515/1000\n",
      "83/83 - 0s - loss: 828.4173 - val_loss: 516.6420\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 0s - loss: 828.3280 - val_loss: 515.9758\n",
      "Epoch 517/1000\n",
      "83/83 - 0s - loss: 827.9532 - val_loss: 515.3192\n",
      "Epoch 518/1000\n",
      "83/83 - 0s - loss: 827.8563 - val_loss: 514.6689\n",
      "Epoch 519/1000\n",
      "83/83 - 0s - loss: 827.3754 - val_loss: 514.0257\n",
      "Epoch 520/1000\n",
      "83/83 - 0s - loss: 826.8364 - val_loss: 513.3633\n",
      "Epoch 521/1000\n",
      "83/83 - 0s - loss: 826.1030 - val_loss: 512.7080\n",
      "Epoch 522/1000\n",
      "83/83 - 0s - loss: 825.4529 - val_loss: 512.0399\n",
      "Epoch 523/1000\n",
      "83/83 - 0s - loss: 825.7126 - val_loss: 511.3890\n",
      "Epoch 524/1000\n",
      "83/83 - 0s - loss: 825.3152 - val_loss: 510.7373\n",
      "Epoch 525/1000\n",
      "83/83 - 0s - loss: 829.8920 - val_loss: 515.1708\n",
      "Epoch 526/1000\n",
      "83/83 - 0s - loss: 834.9982 - val_loss: 523.4164\n",
      "Epoch 527/1000\n",
      "83/83 - 0s - loss: 833.9084 - val_loss: 522.9100\n",
      "Epoch 528/1000\n",
      "83/83 - 0s - loss: 831.6504 - val_loss: 522.2159\n",
      "Epoch 529/1000\n",
      "83/83 - 0s - loss: 832.9333 - val_loss: 521.7115\n",
      "Epoch 530/1000\n",
      "83/83 - 0s - loss: 830.6004 - val_loss: 520.9994\n",
      "Epoch 531/1000\n",
      "83/83 - 0s - loss: 832.0472 - val_loss: 520.5001\n",
      "Epoch 532/1000\n",
      "83/83 - 0s - loss: 829.8354 - val_loss: 519.8138\n",
      "Epoch 533/1000\n",
      "83/83 - 0s - loss: 831.1469 - val_loss: 519.3177\n",
      "Epoch 534/1000\n",
      "83/83 - 0s - loss: 828.9271 - val_loss: 518.6406\n",
      "Epoch 535/1000\n",
      "83/83 - 0s - loss: 830.3956 - val_loss: 518.1500\n",
      "Epoch 536/1000\n",
      "83/83 - 0s - loss: 828.1471 - val_loss: 517.4808\n",
      "Epoch 537/1000\n",
      "83/83 - 0s - loss: 829.4623 - val_loss: 516.9850\n",
      "Epoch 538/1000\n",
      "83/83 - 0s - loss: 827.2711 - val_loss: 516.3247\n",
      "Epoch 539/1000\n",
      "83/83 - 0s - loss: 828.5688 - val_loss: 515.8074\n",
      "Epoch 540/1000\n",
      "83/83 - 0s - loss: 826.7176 - val_loss: 515.1805\n",
      "Epoch 541/1000\n",
      "83/83 - 0s - loss: 827.5428 - val_loss: 514.6447\n",
      "Epoch 542/1000\n",
      "83/83 - 0s - loss: 826.0098 - val_loss: 514.0416\n",
      "Epoch 543/1000\n",
      "83/83 - 0s - loss: 826.3356 - val_loss: 513.4899\n",
      "Epoch 544/1000\n",
      "83/83 - 0s - loss: 825.4299 - val_loss: 512.8955\n",
      "Epoch 545/1000\n",
      "83/83 - 0s - loss: 826.0499 - val_loss: 512.3472\n",
      "Epoch 546/1000\n",
      "83/83 - 0s - loss: 825.1522 - val_loss: 511.7694\n",
      "Epoch 547/1000\n",
      "83/83 - 0s - loss: 826.8547 - val_loss: 511.2488\n",
      "Epoch 548/1000\n",
      "83/83 - 0s - loss: 825.8710 - val_loss: 510.6557\n",
      "Epoch 549/1000\n",
      "83/83 - 0s - loss: 824.9644 - val_loss: 510.0993\n",
      "Epoch 550/1000\n",
      "83/83 - 0s - loss: 844.4918 - val_loss: 536.9396\n",
      "Epoch 551/1000\n",
      "83/83 - 0s - loss: 861.9814 - val_loss: 563.7495\n",
      "Epoch 552/1000\n",
      "83/83 - 0s - loss: 860.3712 - val_loss: 563.2775\n",
      "Epoch 553/1000\n",
      "83/83 - 0s - loss: 859.9472 - val_loss: 562.7882\n",
      "Epoch 554/1000\n",
      "83/83 - 0s - loss: 859.6854 - val_loss: 562.3195\n",
      "Epoch 555/1000\n",
      "83/83 - 0s - loss: 859.2225 - val_loss: 561.8253\n",
      "Epoch 556/1000\n",
      "83/83 - 0s - loss: 859.2039 - val_loss: 561.3688\n",
      "Epoch 557/1000\n",
      "83/83 - 0s - loss: 858.6276 - val_loss: 560.8742\n",
      "Epoch 558/1000\n",
      "83/83 - 0s - loss: 858.5478 - val_loss: 560.4181\n",
      "Epoch 559/1000\n",
      "83/83 - 0s - loss: 857.9641 - val_loss: 559.9241\n",
      "Epoch 560/1000\n",
      "83/83 - 0s - loss: 857.9113 - val_loss: 559.4717\n",
      "Epoch 561/1000\n",
      "83/83 - 0s - loss: 857.2319 - val_loss: 558.9774\n",
      "Epoch 562/1000\n",
      "83/83 - 0s - loss: 857.2584 - val_loss: 558.5245\n",
      "Epoch 563/1000\n",
      "83/83 - 0s - loss: 856.4988 - val_loss: 558.0319\n",
      "Epoch 564/1000\n",
      "83/83 - 0s - loss: 856.5668 - val_loss: 557.5760\n",
      "Epoch 565/1000\n",
      "83/83 - 0s - loss: 855.9612 - val_loss: 557.0836\n",
      "Epoch 566/1000\n",
      "83/83 - 0s - loss: 856.0297 - val_loss: 556.6340\n",
      "Epoch 567/1000\n",
      "83/83 - 0s - loss: 855.1552 - val_loss: 556.1381\n",
      "Epoch 568/1000\n",
      "83/83 - 0s - loss: 855.3569 - val_loss: 555.6837\n",
      "Epoch 569/1000\n",
      "83/83 - 0s - loss: 854.5340 - val_loss: 555.1937\n",
      "Epoch 570/1000\n",
      "83/83 - 0s - loss: 854.7186 - val_loss: 554.7390\n",
      "Epoch 571/1000\n",
      "83/83 - 0s - loss: 853.9117 - val_loss: 554.2521\n",
      "Epoch 572/1000\n",
      "83/83 - 0s - loss: 854.0326 - val_loss: 553.7949\n",
      "Epoch 573/1000\n",
      "83/83 - 0s - loss: 853.2651 - val_loss: 553.3088\n",
      "Epoch 574/1000\n",
      "83/83 - 0s - loss: 853.4313 - val_loss: 552.8541\n",
      "Epoch 575/1000\n",
      "83/83 - 0s - loss: 852.6334 - val_loss: 552.3697\n",
      "Epoch 576/1000\n",
      "83/83 - 0s - loss: 852.7419 - val_loss: 551.9111\n",
      "Epoch 577/1000\n",
      "83/83 - 0s - loss: 852.1232 - val_loss: 551.4395\n",
      "Epoch 578/1000\n",
      "83/83 - 0s - loss: 851.8218 - val_loss: 550.9658\n",
      "Epoch 579/1000\n",
      "83/83 - 0s - loss: 851.5663 - val_loss: 550.4991\n",
      "Epoch 580/1000\n",
      "83/83 - 0s - loss: 851.1119 - val_loss: 550.0209\n",
      "Epoch 581/1000\n",
      "83/83 - 0s - loss: 851.2365 - val_loss: 549.5706\n",
      "Epoch 582/1000\n",
      "83/83 - 0s - loss: 850.3334 - val_loss: 549.0798\n",
      "Epoch 583/1000\n",
      "83/83 - 0s - loss: 850.5919 - val_loss: 548.6302\n",
      "Epoch 584/1000\n",
      "83/83 - 0s - loss: 849.6849 - val_loss: 548.1402\n",
      "Epoch 585/1000\n",
      "83/83 - 0s - loss: 849.9728 - val_loss: 547.6967\n",
      "Epoch 586/1000\n",
      "83/83 - 0s - loss: 848.9975 - val_loss: 547.1979\n",
      "Epoch 587/1000\n",
      "83/83 - 0s - loss: 849.5084 - val_loss: 546.7628\n",
      "Epoch 588/1000\n",
      "83/83 - 0s - loss: 848.1916 - val_loss: 546.2578\n",
      "Epoch 589/1000\n",
      "83/83 - 0s - loss: 849.0270 - val_loss: 545.8242\n",
      "Epoch 590/1000\n",
      "83/83 - 0s - loss: 847.7142 - val_loss: 545.3253\n",
      "Epoch 591/1000\n",
      "83/83 - 0s - loss: 848.3223 - val_loss: 544.8878\n",
      "Epoch 592/1000\n",
      "83/83 - 0s - loss: 846.9167 - val_loss: 544.3901\n",
      "Epoch 593/1000\n",
      "83/83 - 0s - loss: 847.8463 - val_loss: 543.9598\n",
      "Epoch 594/1000\n",
      "83/83 - 0s - loss: 846.2234 - val_loss: 543.4606\n",
      "Epoch 595/1000\n",
      "83/83 - 0s - loss: 846.8712 - val_loss: 543.0150\n",
      "Epoch 596/1000\n",
      "83/83 - 0s - loss: 845.8109 - val_loss: 542.5310\n",
      "Epoch 597/1000\n",
      "83/83 - 0s - loss: 846.1160 - val_loss: 542.0823\n",
      "Epoch 598/1000\n",
      "83/83 - 0s - loss: 845.1268 - val_loss: 541.5955\n",
      "Epoch 599/1000\n",
      "83/83 - 0s - loss: 845.5267 - val_loss: 541.1502\n",
      "Epoch 600/1000\n",
      "83/83 - 0s - loss: 844.4259 - val_loss: 540.6605\n",
      "Epoch 601/1000\n",
      "83/83 - 0s - loss: 844.8987 - val_loss: 540.2150\n",
      "Epoch 602/1000\n",
      "83/83 - 0s - loss: 843.8314 - val_loss: 539.7297\n",
      "Epoch 603/1000\n",
      "83/83 - 0s - loss: 844.3365 - val_loss: 539.2819\n",
      "Epoch 604/1000\n",
      "83/83 - 0s - loss: 843.2077 - val_loss: 538.7941\n",
      "Epoch 605/1000\n",
      "83/83 - 0s - loss: 844.0142 - val_loss: 538.3593\n",
      "Epoch 606/1000\n",
      "83/83 - 0s - loss: 842.5104 - val_loss: 537.8663\n",
      "Epoch 607/1000\n",
      "83/83 - 0s - loss: 843.4753 - val_loss: 537.4360\n",
      "Epoch 608/1000\n",
      "83/83 - 0s - loss: 841.7141 - val_loss: 536.9398\n",
      "Epoch 609/1000\n",
      "83/83 - 0s - loss: 842.8837 - val_loss: 536.5101\n",
      "Epoch 610/1000\n",
      "83/83 - 0s - loss: 841.3217 - val_loss: 536.0253\n",
      "Epoch 611/1000\n",
      "83/83 - 0s - loss: 841.5609 - val_loss: 535.5750\n",
      "Epoch 612/1000\n",
      "83/83 - 0s - loss: 840.6639 - val_loss: 535.0978\n",
      "Epoch 613/1000\n",
      "83/83 - 0s - loss: 840.7245 - val_loss: 534.6334\n",
      "Epoch 614/1000\n",
      "83/83 - 0s - loss: 840.3682 - val_loss: 534.1696\n",
      "Epoch 615/1000\n",
      "83/83 - 0s - loss: 839.9716 - val_loss: 533.7062\n",
      "Epoch 616/1000\n",
      "83/83 - 0s - loss: 839.5240 - val_loss: 533.2382\n",
      "Epoch 617/1000\n",
      "83/83 - 0s - loss: 839.1152 - val_loss: 532.7640\n",
      "Epoch 618/1000\n",
      "83/83 - 0s - loss: 839.0909 - val_loss: 532.3030\n",
      "Epoch 619/1000\n",
      "83/83 - 0s - loss: 838.5896 - val_loss: 531.8356\n",
      "Epoch 620/1000\n",
      "83/83 - 0s - loss: 838.0917 - val_loss: 531.3619\n",
      "Epoch 621/1000\n",
      "83/83 - 0s - loss: 837.9932 - val_loss: 530.8938\n",
      "Epoch 622/1000\n",
      "83/83 - 0s - loss: 837.8073 - val_loss: 530.4294\n",
      "Epoch 623/1000\n",
      "83/83 - 0s - loss: 837.4156 - val_loss: 529.9614\n",
      "Epoch 624/1000\n",
      "83/83 - 0s - loss: 837.2754 - val_loss: 529.4955\n",
      "Epoch 625/1000\n",
      "83/83 - 0s - loss: 837.0665 - val_loss: 529.0417\n",
      "Epoch 626/1000\n",
      "83/83 - 0s - loss: 836.2939 - val_loss: 528.5630\n",
      "Epoch 627/1000\n",
      "83/83 - 0s - loss: 836.4370 - val_loss: 528.1112\n",
      "Epoch 628/1000\n",
      "83/83 - 0s - loss: 835.4762 - val_loss: 527.6338\n",
      "Epoch 629/1000\n",
      "83/83 - 0s - loss: 835.6158 - val_loss: 527.1678\n",
      "Epoch 630/1000\n",
      "83/83 - 0s - loss: 835.3282 - val_loss: 526.7102\n",
      "Epoch 631/1000\n",
      "83/83 - 0s - loss: 834.6205 - val_loss: 526.2363\n",
      "Epoch 632/1000\n",
      "83/83 - 0s - loss: 834.6599 - val_loss: 525.7722\n",
      "Epoch 633/1000\n",
      "83/83 - 0s - loss: 834.4360 - val_loss: 525.3058\n",
      "Epoch 634/1000\n",
      "83/83 - 0s - loss: 834.3991 - val_loss: 524.8486\n",
      "Epoch 635/1000\n",
      "83/83 - 0s - loss: 834.3907 - val_loss: 524.3895\n",
      "Epoch 636/1000\n",
      "83/83 - 0s - loss: 833.7603 - val_loss: 523.9245\n",
      "Epoch 637/1000\n",
      "83/83 - 0s - loss: 857.1252 - val_loss: 555.1835\n",
      "Epoch 638/1000\n",
      "83/83 - 0s - loss: 854.6663 - val_loss: 554.7863\n",
      "Epoch 639/1000\n",
      "83/83 - 0s - loss: 854.2003 - val_loss: 554.3636\n",
      "Epoch 640/1000\n",
      "83/83 - 0s - loss: 854.0563 - val_loss: 553.9576\n",
      "Epoch 641/1000\n",
      "83/83 - 0s - loss: 853.4559 - val_loss: 553.5238\n",
      "Epoch 642/1000\n",
      "83/83 - 0s - loss: 853.5448 - val_loss: 553.1234\n",
      "Epoch 643/1000\n",
      "83/83 - 0s - loss: 852.7775 - val_loss: 552.6874\n",
      "Epoch 644/1000\n",
      "83/83 - 0s - loss: 852.8429 - val_loss: 552.2825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 645/1000\n",
      "83/83 - 0s - loss: 852.1600 - val_loss: 551.8434\n",
      "Epoch 646/1000\n",
      "83/83 - 0s - loss: 852.3448 - val_loss: 551.4413\n",
      "Epoch 647/1000\n",
      "83/83 - 0s - loss: 851.5513 - val_loss: 551.0023\n",
      "Epoch 648/1000\n",
      "83/83 - 0s - loss: 851.8259 - val_loss: 550.6019\n",
      "Epoch 649/1000\n",
      "83/83 - 0s - loss: 851.0659 - val_loss: 550.1622\n",
      "Epoch 650/1000\n",
      "83/83 - 0s - loss: 851.3439 - val_loss: 549.7723\n",
      "Epoch 651/1000\n",
      "83/83 - 0s - loss: 850.1823 - val_loss: 549.3211\n",
      "Epoch 652/1000\n",
      "83/83 - 0s - loss: 850.6940 - val_loss: 548.9210\n",
      "Epoch 653/1000\n",
      "83/83 - 0s - loss: 849.9266 - val_loss: 548.4823\n",
      "Epoch 654/1000\n",
      "83/83 - 0s - loss: 850.2216 - val_loss: 548.0921\n",
      "Epoch 655/1000\n",
      "83/83 - 0s - loss: 849.1326 - val_loss: 547.6412\n",
      "Epoch 656/1000\n",
      "83/83 - 0s - loss: 849.8469 - val_loss: 547.2590\n",
      "Epoch 657/1000\n",
      "83/83 - 0s - loss: 848.6666 - val_loss: 546.8042\n",
      "Epoch 658/1000\n",
      "83/83 - 0s - loss: 849.5919 - val_loss: 546.4355\n",
      "Epoch 659/1000\n",
      "83/83 - 0s - loss: 847.9743 - val_loss: 545.9709\n",
      "Epoch 660/1000\n",
      "83/83 - 0s - loss: 849.0582 - val_loss: 545.6122\n",
      "Epoch 661/1000\n",
      "83/83 - 0s - loss: 847.2246 - val_loss: 545.1407\n",
      "Epoch 662/1000\n",
      "83/83 - 0s - loss: 848.0865 - val_loss: 544.7511\n",
      "Epoch 663/1000\n",
      "83/83 - 0s - loss: 846.7587 - val_loss: 544.3068\n",
      "Epoch 664/1000\n",
      "83/83 - 0s - loss: 847.4514 - val_loss: 543.9139\n",
      "Epoch 665/1000\n",
      "83/83 - 0s - loss: 846.5095 - val_loss: 543.4742\n",
      "Epoch 666/1000\n",
      "83/83 - 0s - loss: 847.0753 - val_loss: 543.0891\n",
      "Epoch 667/1000\n",
      "83/83 - 0s - loss: 845.5447 - val_loss: 542.6414\n",
      "Epoch 668/1000\n",
      "83/83 - 0s - loss: 846.3644 - val_loss: 542.2521\n",
      "Epoch 669/1000\n",
      "83/83 - 0s - loss: 844.9806 - val_loss: 541.8082\n",
      "Epoch 670/1000\n",
      "83/83 - 0s - loss: 845.8074 - val_loss: 541.4179\n",
      "Epoch 671/1000\n",
      "83/83 - 0s - loss: 844.6846 - val_loss: 540.9794\n",
      "Epoch 672/1000\n",
      "83/83 - 0s - loss: 845.1244 - val_loss: 540.5815\n",
      "Epoch 673/1000\n",
      "83/83 - 0s - loss: 844.3212 - val_loss: 540.1559\n",
      "Epoch 674/1000\n",
      "83/83 - 0s - loss: 844.3553 - val_loss: 539.7481\n",
      "Epoch 675/1000\n",
      "83/83 - 0s - loss: 843.6985 - val_loss: 539.3290\n",
      "Epoch 676/1000\n",
      "83/83 - 0s - loss: 843.6672 - val_loss: 538.9197\n",
      "Epoch 677/1000\n",
      "83/83 - 0s - loss: 843.0441 - val_loss: 538.4948\n",
      "Epoch 678/1000\n",
      "83/83 - 0s - loss: 843.0088 - val_loss: 538.0844\n",
      "Epoch 679/1000\n",
      "83/83 - 0s - loss: 842.5244 - val_loss: 537.6613\n",
      "Epoch 680/1000\n",
      "83/83 - 0s - loss: 842.5755 - val_loss: 537.2527\n",
      "Epoch 681/1000\n",
      "83/83 - 0s - loss: 841.9305 - val_loss: 536.8299\n",
      "Epoch 682/1000\n",
      "83/83 - 0s - loss: 841.9399 - val_loss: 536.4185\n",
      "Epoch 683/1000\n",
      "83/83 - 0s - loss: 841.4091 - val_loss: 536.0024\n",
      "Epoch 684/1000\n",
      "83/83 - 0s - loss: 841.1256 - val_loss: 535.5825\n",
      "Epoch 685/1000\n",
      "83/83 - 0s - loss: 840.9935 - val_loss: 535.1652\n",
      "Epoch 686/1000\n",
      "83/83 - 0s - loss: 840.9135 - val_loss: 534.7524\n",
      "Epoch 687/1000\n",
      "83/83 - 0s - loss: 840.6322 - val_loss: 534.3433\n",
      "Epoch 688/1000\n",
      "83/83 - 0s - loss: 840.2835 - val_loss: 533.9289\n",
      "Epoch 689/1000\n",
      "83/83 - 0s - loss: 840.8240 - val_loss: 533.5291\n",
      "Epoch 690/1000\n",
      "83/83 - 0s - loss: 839.6301 - val_loss: 533.0868\n",
      "Epoch 691/1000\n",
      "83/83 - 0s - loss: 840.1098 - val_loss: 532.6911\n",
      "Epoch 692/1000\n",
      "83/83 - 0s - loss: 839.3385 - val_loss: 532.2805\n",
      "Epoch 693/1000\n",
      "83/83 - 0s - loss: 838.9825 - val_loss: 531.8649\n",
      "Epoch 694/1000\n",
      "83/83 - 0s - loss: 838.7203 - val_loss: 531.4476\n",
      "Epoch 695/1000\n",
      "83/83 - 0s - loss: 839.0787 - val_loss: 531.0557\n",
      "Epoch 696/1000\n",
      "83/83 - 0s - loss: 837.9128 - val_loss: 530.6346\n",
      "Epoch 697/1000\n",
      "83/83 - 0s - loss: 837.7115 - val_loss: 530.2257\n",
      "Epoch 698/1000\n",
      "83/83 - 0s - loss: 837.3151 - val_loss: 529.8071\n",
      "Epoch 699/1000\n",
      "83/83 - 0s - loss: 837.0522 - val_loss: 529.3992\n",
      "Epoch 700/1000\n",
      "83/83 - 0s - loss: 836.5045 - val_loss: 528.9747\n",
      "Epoch 701/1000\n",
      "83/83 - 0s - loss: 836.5638 - val_loss: 528.5630\n",
      "Epoch 702/1000\n",
      "83/83 - 0s - loss: 836.2228 - val_loss: 528.1473\n",
      "Epoch 703/1000\n",
      "83/83 - 0s - loss: 835.8331 - val_loss: 527.7367\n",
      "Epoch 704/1000\n",
      "83/83 - 0s - loss: 835.2556 - val_loss: 527.3082\n",
      "Epoch 705/1000\n",
      "83/83 - 0s - loss: 835.4237 - val_loss: 526.9031\n",
      "Epoch 706/1000\n",
      "83/83 - 0s - loss: 834.7643 - val_loss: 526.4782\n",
      "Epoch 707/1000\n",
      "83/83 - 0s - loss: 834.6341 - val_loss: 526.0628\n",
      "Epoch 708/1000\n",
      "83/83 - 0s - loss: 834.5359 - val_loss: 525.6527\n",
      "Epoch 709/1000\n",
      "83/83 - 0s - loss: 833.9379 - val_loss: 525.2302\n",
      "Epoch 710/1000\n",
      "83/83 - 0s - loss: 833.9382 - val_loss: 524.8163\n",
      "Epoch 711/1000\n",
      "83/83 - 0s - loss: 833.4691 - val_loss: 524.4034\n",
      "Epoch 712/1000\n",
      "83/83 - 0s - loss: 833.1241 - val_loss: 523.9810\n",
      "Epoch 713/1000\n",
      "83/83 - 0s - loss: 832.9422 - val_loss: 523.5661\n",
      "Epoch 714/1000\n",
      "83/83 - 0s - loss: 832.7780 - val_loss: 523.1489\n",
      "Epoch 715/1000\n",
      "83/83 - 0s - loss: 832.5238 - val_loss: 522.7361\n",
      "Epoch 716/1000\n",
      "83/83 - 0s - loss: 832.2963 - val_loss: 522.3210\n",
      "Epoch 717/1000\n",
      "83/83 - 0s - loss: 831.9384 - val_loss: 521.9144\n",
      "Epoch 718/1000\n",
      "83/83 - 0s - loss: 831.3447 - val_loss: 521.4859\n",
      "Epoch 719/1000\n",
      "83/83 - 0s - loss: 831.4706 - val_loss: 521.0963\n",
      "Epoch 720/1000\n",
      "83/83 - 0s - loss: 830.3288 - val_loss: 520.6454\n",
      "Epoch 721/1000\n",
      "83/83 - 0s - loss: 831.1844 - val_loss: 520.2645\n",
      "Epoch 722/1000\n",
      "83/83 - 0s - loss: 829.7213 - val_loss: 519.8094\n",
      "Epoch 723/1000\n",
      "83/83 - 0s - loss: 830.7846 - val_loss: 519.4263\n",
      "Epoch 724/1000\n",
      "83/83 - 0s - loss: 829.1951 - val_loss: 518.9824\n",
      "Epoch 725/1000\n",
      "83/83 - 0s - loss: 829.7538 - val_loss: 518.5824\n",
      "Epoch 726/1000\n",
      "83/83 - 0s - loss: 828.8135 - val_loss: 518.1451\n",
      "Epoch 727/1000\n",
      "83/83 - 0s - loss: 829.3945 - val_loss: 517.7479\n",
      "Epoch 728/1000\n",
      "83/83 - 0s - loss: 828.2251 - val_loss: 517.3177\n",
      "Epoch 729/1000\n",
      "83/83 - 0s - loss: 828.5244 - val_loss: 516.9147\n",
      "Epoch 730/1000\n",
      "83/83 - 0s - loss: 827.5225 - val_loss: 516.4833\n",
      "Epoch 731/1000\n",
      "83/83 - 0s - loss: 827.8868 - val_loss: 516.0778\n",
      "Epoch 732/1000\n",
      "83/83 - 0s - loss: 827.0525 - val_loss: 515.6497\n",
      "Epoch 733/1000\n",
      "83/83 - 0s - loss: 827.2669 - val_loss: 515.2394\n",
      "Epoch 734/1000\n",
      "83/83 - 0s - loss: 826.6313 - val_loss: 514.8128\n",
      "Epoch 735/1000\n",
      "83/83 - 0s - loss: 826.9062 - val_loss: 514.4054\n",
      "Epoch 736/1000\n",
      "83/83 - 0s - loss: 826.1725 - val_loss: 513.9807\n",
      "Epoch 737/1000\n",
      "83/83 - 0s - loss: 826.3977 - val_loss: 513.5729\n",
      "Epoch 738/1000\n",
      "83/83 - 0s - loss: 825.8939 - val_loss: 513.1595\n",
      "Epoch 739/1000\n",
      "83/83 - 0s - loss: 825.7002 - val_loss: 512.7504\n",
      "Epoch 740/1000\n",
      "83/83 - 0s - loss: 825.4371 - val_loss: 512.3398\n",
      "Epoch 741/1000\n",
      "83/83 - 0s - loss: 825.4834 - val_loss: 511.9145\n",
      "Epoch 742/1000\n",
      "83/83 - 0s - loss: 825.2138 - val_loss: 511.5245\n",
      "Epoch 743/1000\n",
      "83/83 - 0s - loss: 823.8673 - val_loss: 511.0877\n",
      "Epoch 744/1000\n",
      "83/83 - 0s - loss: 824.3056 - val_loss: 510.6856\n",
      "Epoch 745/1000\n",
      "83/83 - 0s - loss: 823.3928 - val_loss: 510.2560\n",
      "Epoch 746/1000\n",
      "83/83 - 0s - loss: 823.6422 - val_loss: 509.8564\n",
      "Epoch 747/1000\n",
      "83/83 - 0s - loss: 822.6784 - val_loss: 509.4206\n",
      "Epoch 748/1000\n",
      "83/83 - 0s - loss: 823.1497 - val_loss: 509.0222\n",
      "Epoch 749/1000\n",
      "83/83 - 0s - loss: 822.0938 - val_loss: 508.5878\n",
      "Epoch 750/1000\n",
      "83/83 - 0s - loss: 822.5800 - val_loss: 508.1886\n",
      "Epoch 751/1000\n",
      "83/83 - 0s - loss: 821.5088 - val_loss: 507.7544\n",
      "Epoch 752/1000\n",
      "83/83 - 0s - loss: 822.0342 - val_loss: 507.3541\n",
      "Epoch 753/1000\n",
      "83/83 - 0s - loss: 821.2110 - val_loss: 506.9253\n",
      "Epoch 754/1000\n",
      "83/83 - 0s - loss: 821.5601 - val_loss: 506.5203\n",
      "Epoch 755/1000\n",
      "83/83 - 0s - loss: 821.5700 - val_loss: 506.1036\n",
      "Epoch 756/1000\n",
      "83/83 - 0s - loss: 821.7097 - val_loss: 505.6959\n",
      "Epoch 757/1000\n",
      "83/83 - 0s - loss: 820.9557 - val_loss: 505.2731\n",
      "Epoch 758/1000\n",
      "83/83 - 0s - loss: 823.0692 - val_loss: 505.5663\n",
      "Epoch 759/1000\n",
      "83/83 - 0s - loss: 819.4547 - val_loss: 504.9608\n",
      "Epoch 760/1000\n",
      "83/83 - 0s - loss: 820.6235 - val_loss: 504.4694\n",
      "Epoch 761/1000\n",
      "83/83 - 0s - loss: 819.1016 - val_loss: 503.9314\n",
      "Epoch 762/1000\n",
      "83/83 - 0s - loss: 819.7400 - val_loss: 503.4596\n",
      "Epoch 763/1000\n",
      "83/83 - 0s - loss: 818.4510 - val_loss: 502.9429\n",
      "Epoch 764/1000\n",
      "83/83 - 0s - loss: 818.9827 - val_loss: 502.4800\n",
      "Epoch 765/1000\n",
      "83/83 - 0s - loss: 817.6953 - val_loss: 501.9720\n",
      "Epoch 766/1000\n",
      "83/83 - 0s - loss: 818.2579 - val_loss: 501.5155\n",
      "Epoch 767/1000\n",
      "83/83 - 0s - loss: 816.8306 - val_loss: 501.0120\n",
      "Epoch 768/1000\n",
      "83/83 - 0s - loss: 817.2878 - val_loss: 500.5446\n",
      "Epoch 769/1000\n",
      "83/83 - 0s - loss: 816.7155 - val_loss: 500.0621\n",
      "Epoch 770/1000\n",
      "83/83 - 0s - loss: 816.8341 - val_loss: 499.6097\n",
      "Epoch 771/1000\n",
      "83/83 - 0s - loss: 815.7171 - val_loss: 499.1099\n",
      "Epoch 772/1000\n",
      "83/83 - 0s - loss: 816.3737 - val_loss: 498.6656\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 0s - loss: 815.2876 - val_loss: 498.1714\n",
      "Epoch 774/1000\n",
      "83/83 - 0s - loss: 816.6335 - val_loss: 497.7486\n",
      "Epoch 775/1000\n",
      "83/83 - 0s - loss: 814.2546 - val_loss: 497.2452\n",
      "Epoch 776/1000\n",
      "83/83 - 0s - loss: 815.4356 - val_loss: 496.7962\n",
      "Epoch 777/1000\n",
      "83/83 - 0s - loss: 814.1611 - val_loss: 496.3210\n",
      "Epoch 778/1000\n",
      "83/83 - 0s - loss: 814.6922 - val_loss: 495.8843\n",
      "Epoch 779/1000\n",
      "83/83 - 0s - loss: 813.4471 - val_loss: 495.4045\n",
      "Epoch 780/1000\n",
      "83/83 - 0s - loss: 813.2928 - val_loss: 494.9285\n",
      "Epoch 781/1000\n",
      "83/83 - 0s - loss: 814.0037 - val_loss: 494.5092\n",
      "Epoch 782/1000\n",
      "83/83 - 0s - loss: 811.9106 - val_loss: 494.0064\n",
      "Epoch 783/1000\n",
      "83/83 - 0s - loss: 813.1803 - val_loss: 493.5732\n",
      "Epoch 784/1000\n",
      "83/83 - 0s - loss: 812.0169 - val_loss: 493.0972\n",
      "Epoch 785/1000\n",
      "83/83 - 0s - loss: 812.2724 - val_loss: 492.6622\n",
      "Epoch 786/1000\n",
      "83/83 - 0s - loss: 810.9838 - val_loss: 492.1781\n",
      "Epoch 787/1000\n",
      "83/83 - 0s - loss: 811.3768 - val_loss: 491.7339\n",
      "Epoch 788/1000\n",
      "83/83 - 0s - loss: 810.4597 - val_loss: 491.2525\n",
      "Epoch 789/1000\n",
      "83/83 - 0s - loss: 810.8948 - val_loss: 490.8093\n",
      "Epoch 790/1000\n",
      "83/83 - 0s - loss: 809.7016 - val_loss: 490.3349\n",
      "Epoch 791/1000\n",
      "83/83 - 0s - loss: 809.7662 - val_loss: 489.8786\n",
      "Epoch 792/1000\n",
      "83/83 - 0s - loss: 809.2595 - val_loss: 489.4094\n",
      "Epoch 793/1000\n",
      "83/83 - 0s - loss: 809.1884 - val_loss: 488.9604\n",
      "Epoch 794/1000\n",
      "83/83 - 0s - loss: 808.1960 - val_loss: 488.4641\n",
      "Epoch 795/1000\n",
      "83/83 - 0s - loss: 809.3718 - val_loss: 488.0380\n",
      "Epoch 796/1000\n",
      "83/83 - 0s - loss: 807.9733 - val_loss: 487.5488\n",
      "Epoch 797/1000\n",
      "83/83 - 0s - loss: 837.1313 - val_loss: 526.6940\n",
      "Epoch 798/1000\n",
      "83/83 - 0s - loss: 834.1642 - val_loss: 526.2676\n",
      "Epoch 799/1000\n",
      "83/83 - 0s - loss: 833.8494 - val_loss: 525.8423\n",
      "Epoch 800/1000\n",
      "83/83 - 0s - loss: 833.5415 - val_loss: 525.4155\n",
      "Epoch 801/1000\n",
      "83/83 - 0s - loss: 833.2943 - val_loss: 524.9921\n",
      "Epoch 802/1000\n",
      "83/83 - 0s - loss: 832.9897 - val_loss: 524.5662\n",
      "Epoch 803/1000\n",
      "83/83 - 0s - loss: 832.7137 - val_loss: 524.1449\n",
      "Epoch 804/1000\n",
      "83/83 - 0s - loss: 832.3862 - val_loss: 523.7181\n",
      "Epoch 805/1000\n",
      "83/83 - 0s - loss: 832.1830 - val_loss: 523.2991\n",
      "Epoch 806/1000\n",
      "83/83 - 0s - loss: 831.8143 - val_loss: 522.8737\n",
      "Epoch 807/1000\n",
      "83/83 - 0s - loss: 831.5970 - val_loss: 522.4549\n",
      "Epoch 808/1000\n",
      "83/83 - 0s - loss: 831.2209 - val_loss: 522.0298\n",
      "Epoch 809/1000\n",
      "83/83 - 0s - loss: 830.9259 - val_loss: 521.6082\n",
      "Epoch 810/1000\n",
      "83/83 - 0s - loss: 830.6201 - val_loss: 521.1841\n",
      "Epoch 811/1000\n",
      "83/83 - 0s - loss: 830.3729 - val_loss: 520.7617\n",
      "Epoch 812/1000\n",
      "83/83 - 0s - loss: 830.1290 - val_loss: 520.3427\n",
      "Epoch 813/1000\n",
      "83/83 - 0s - loss: 829.8551 - val_loss: 519.9196\n",
      "Epoch 814/1000\n",
      "83/83 - 0s - loss: 829.5756 - val_loss: 519.5026\n",
      "Epoch 815/1000\n",
      "83/83 - 0s - loss: 829.2565 - val_loss: 519.0767\n",
      "Epoch 816/1000\n",
      "83/83 - 0s - loss: 829.1796 - val_loss: 518.6652\n",
      "Epoch 817/1000\n",
      "83/83 - 0s - loss: 828.6062 - val_loss: 518.2378\n",
      "Epoch 818/1000\n",
      "83/83 - 0s - loss: 828.5010 - val_loss: 517.8192\n",
      "Epoch 819/1000\n",
      "83/83 - 0s - loss: 828.2071 - val_loss: 517.3949\n",
      "Epoch 820/1000\n",
      "83/83 - 0s - loss: 828.2824 - val_loss: 516.9874\n",
      "Epoch 821/1000\n",
      "83/83 - 0s - loss: 827.7046 - val_loss: 516.5695\n",
      "Epoch 822/1000\n",
      "83/83 - 0s - loss: 827.2998 - val_loss: 516.1463\n",
      "Epoch 823/1000\n",
      "83/83 - 0s - loss: 827.1475 - val_loss: 515.7358\n",
      "Epoch 824/1000\n",
      "83/83 - 0s - loss: 826.6307 - val_loss: 515.3077\n",
      "Epoch 825/1000\n",
      "83/83 - 0s - loss: 826.7113 - val_loss: 514.8912\n",
      "Epoch 826/1000\n",
      "83/83 - 0s - loss: 826.1688 - val_loss: 514.4681\n",
      "Epoch 827/1000\n",
      "83/83 - 0s - loss: 826.2628 - val_loss: 514.0595\n",
      "Epoch 828/1000\n",
      "83/83 - 0s - loss: 825.6265 - val_loss: 513.6432\n",
      "Epoch 829/1000\n",
      "83/83 - 0s - loss: 825.2825 - val_loss: 513.2196\n",
      "Epoch 830/1000\n",
      "83/83 - 0s - loss: 825.2493 - val_loss: 512.8098\n",
      "Epoch 831/1000\n",
      "83/83 - 0s - loss: 824.7150 - val_loss: 512.3892\n",
      "Epoch 832/1000\n",
      "83/83 - 0s - loss: 824.4403 - val_loss: 511.9706\n",
      "Epoch 833/1000\n",
      "83/83 - 0s - loss: 824.2667 - val_loss: 511.5580\n",
      "Epoch 834/1000\n",
      "83/83 - 0s - loss: 823.6038 - val_loss: 511.1319\n",
      "Epoch 835/1000\n",
      "83/83 - 0s - loss: 823.5706 - val_loss: 510.7151\n",
      "Epoch 836/1000\n",
      "83/83 - 0s - loss: 823.1837 - val_loss: 510.2980\n",
      "Epoch 837/1000\n",
      "83/83 - 0s - loss: 822.8773 - val_loss: 509.8748\n",
      "Epoch 838/1000\n",
      "83/83 - 0s - loss: 822.7869 - val_loss: 509.4638\n",
      "Epoch 839/1000\n",
      "83/83 - 0s - loss: 822.1191 - val_loss: 509.0356\n",
      "Epoch 840/1000\n",
      "83/83 - 0s - loss: 822.3687 - val_loss: 508.6230\n",
      "Epoch 841/1000\n",
      "83/83 - 0s - loss: 821.8941 - val_loss: 508.2008\n",
      "Epoch 842/1000\n",
      "83/83 - 0s - loss: 821.9429 - val_loss: 507.7891\n",
      "Epoch 843/1000\n",
      "83/83 - 0s - loss: 821.4685 - val_loss: 507.3806\n",
      "Epoch 844/1000\n",
      "83/83 - 0s - loss: 820.7344 - val_loss: 506.9539\n",
      "Epoch 845/1000\n",
      "83/83 - 0s - loss: 820.7484 - val_loss: 506.5422\n",
      "Epoch 846/1000\n",
      "83/83 - 0s - loss: 820.1055 - val_loss: 506.1152\n",
      "Epoch 847/1000\n",
      "83/83 - 0s - loss: 820.1866 - val_loss: 505.7013\n",
      "Epoch 848/1000\n",
      "83/83 - 0s - loss: 819.8083 - val_loss: 505.2866\n",
      "Epoch 849/1000\n",
      "83/83 - 0s - loss: 819.3335 - val_loss: 504.8620\n",
      "Epoch 850/1000\n",
      "83/83 - 0s - loss: 819.2351 - val_loss: 504.4454\n",
      "Epoch 851/1000\n",
      "83/83 - 0s - loss: 819.0157 - val_loss: 504.0334\n",
      "Epoch 852/1000\n",
      "83/83 - 0s - loss: 818.3403 - val_loss: 503.6067\n",
      "Epoch 853/1000\n",
      "83/83 - 0s - loss: 818.3268 - val_loss: 503.1912\n",
      "Epoch 854/1000\n",
      "83/83 - 0s - loss: 817.8453 - val_loss: 502.7690\n",
      "Epoch 855/1000\n",
      "83/83 - 0s - loss: 817.7815 - val_loss: 502.3519\n",
      "Epoch 856/1000\n",
      "83/83 - 0s - loss: 817.5522 - val_loss: 501.9314\n",
      "Epoch 857/1000\n",
      "83/83 - 0s - loss: 817.5273 - val_loss: 501.5225\n",
      "Epoch 858/1000\n",
      "83/83 - 0s - loss: 816.9452 - val_loss: 501.1078\n",
      "Epoch 859/1000\n",
      "83/83 - 0s - loss: 816.4562 - val_loss: 500.6847\n",
      "Epoch 860/1000\n",
      "83/83 - 0s - loss: 816.5288 - val_loss: 500.2772\n",
      "Epoch 861/1000\n",
      "83/83 - 0s - loss: 815.9213 - val_loss: 499.8551\n",
      "Epoch 862/1000\n",
      "83/83 - 0s - loss: 815.5170 - val_loss: 499.4312\n",
      "Epoch 863/1000\n",
      "83/83 - 0s - loss: 815.7117 - val_loss: 499.0267\n",
      "Epoch 864/1000\n",
      "83/83 - 0s - loss: 814.8395 - val_loss: 498.5945\n",
      "Epoch 865/1000\n",
      "83/83 - 0s - loss: 815.1600 - val_loss: 498.1905\n",
      "Epoch 866/1000\n",
      "83/83 - 0s - loss: 814.4695 - val_loss: 497.7635\n",
      "Epoch 867/1000\n",
      "83/83 - 0s - loss: 814.4297 - val_loss: 497.3443\n",
      "Epoch 868/1000\n",
      "83/83 - 0s - loss: 814.3422 - val_loss: 496.9349\n",
      "Epoch 869/1000\n",
      "83/83 - 0s - loss: 813.7045 - val_loss: 496.5201\n",
      "Epoch 870/1000\n",
      "83/83 - 0s - loss: 813.2553 - val_loss: 496.0981\n",
      "Epoch 871/1000\n",
      "83/83 - 0s - loss: 813.1677 - val_loss: 495.6837\n",
      "Epoch 872/1000\n",
      "83/83 - 0s - loss: 812.8190 - val_loss: 495.2682\n",
      "Epoch 873/1000\n",
      "83/83 - 0s - loss: 812.4509 - val_loss: 494.8495\n",
      "Epoch 874/1000\n",
      "83/83 - 0s - loss: 812.0807 - val_loss: 494.4299\n",
      "Epoch 875/1000\n",
      "83/83 - 0s - loss: 811.9161 - val_loss: 494.0141\n",
      "Epoch 876/1000\n",
      "83/83 - 0s - loss: 811.4894 - val_loss: 493.5949\n",
      "Epoch 877/1000\n",
      "83/83 - 0s - loss: 811.2228 - val_loss: 493.1750\n",
      "Epoch 878/1000\n",
      "83/83 - 0s - loss: 811.0318 - val_loss: 492.7625\n",
      "Epoch 879/1000\n",
      "83/83 - 0s - loss: 810.3450 - val_loss: 492.3344\n",
      "Epoch 880/1000\n",
      "83/83 - 0s - loss: 810.5184 - val_loss: 491.9253\n",
      "Epoch 881/1000\n",
      "83/83 - 0s - loss: 809.8464 - val_loss: 491.4959\n",
      "Epoch 882/1000\n",
      "83/83 - 0s - loss: 809.9452 - val_loss: 491.0837\n",
      "Epoch 883/1000\n",
      "83/83 - 0s - loss: 809.2903 - val_loss: 490.6567\n",
      "Epoch 884/1000\n",
      "83/83 - 0s - loss: 809.4410 - val_loss: 490.2439\n",
      "Epoch 885/1000\n",
      "83/83 - 0s - loss: 809.0668 - val_loss: 489.8238\n",
      "Epoch 886/1000\n",
      "83/83 - 0s - loss: 809.1628 - val_loss: 489.4213\n",
      "Epoch 887/1000\n",
      "83/83 - 0s - loss: 808.3956 - val_loss: 488.9931\n",
      "Epoch 888/1000\n",
      "83/83 - 0s - loss: 808.8284 - val_loss: 488.5985\n",
      "Epoch 889/1000\n",
      "83/83 - 0s - loss: 807.6809 - val_loss: 488.1651\n",
      "Epoch 890/1000\n",
      "83/83 - 0s - loss: 808.1012 - val_loss: 487.7785\n",
      "Epoch 891/1000\n",
      "83/83 - 0s - loss: 806.5956 - val_loss: 487.3253\n",
      "Epoch 892/1000\n",
      "83/83 - 0s - loss: 808.1585 - val_loss: 486.9416\n",
      "Epoch 893/1000\n",
      "83/83 - 0s - loss: 806.4363 - val_loss: 486.4923\n",
      "Epoch 894/1000\n",
      "83/83 - 0s - loss: 807.5668 - val_loss: 486.1035\n",
      "Epoch 895/1000\n",
      "83/83 - 0s - loss: 805.9950 - val_loss: 485.6754\n",
      "Epoch 896/1000\n",
      "83/83 - 0s - loss: 806.2848 - val_loss: 485.2714\n",
      "Epoch 897/1000\n",
      "83/83 - 0s - loss: 805.3311 - val_loss: 484.8448\n",
      "Epoch 898/1000\n",
      "83/83 - 0s - loss: 805.6487 - val_loss: 484.4408\n",
      "Epoch 899/1000\n",
      "83/83 - 0s - loss: 804.7883 - val_loss: 484.0168\n",
      "Epoch 900/1000\n",
      "83/83 - 0s - loss: 804.9191 - val_loss: 483.6058\n",
      "Epoch 901/1000\n",
      "83/83 - 0s - loss: 804.3274 - val_loss: 483.1885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1000\n",
      "83/83 - 0s - loss: 804.0408 - val_loss: 482.7689\n",
      "Epoch 903/1000\n",
      "83/83 - 0s - loss: 803.7687 - val_loss: 482.3521\n",
      "Epoch 904/1000\n",
      "83/83 - 0s - loss: 803.6327 - val_loss: 481.9418\n",
      "Epoch 905/1000\n",
      "83/83 - 0s - loss: 802.9297 - val_loss: 481.5174\n",
      "Epoch 906/1000\n",
      "83/83 - 0s - loss: 803.3425 - val_loss: 481.1105\n",
      "Epoch 907/1000\n",
      "83/83 - 0s - loss: 802.3594 - val_loss: 480.6774\n",
      "Epoch 908/1000\n",
      "83/83 - 0s - loss: 802.8057 - val_loss: 480.2725\n",
      "Epoch 909/1000\n",
      "83/83 - 0s - loss: 801.8324 - val_loss: 479.8491\n",
      "Epoch 910/1000\n",
      "83/83 - 0s - loss: 801.8359 - val_loss: 479.4355\n",
      "Epoch 911/1000\n",
      "83/83 - 0s - loss: 801.2720 - val_loss: 479.0143\n",
      "Epoch 912/1000\n",
      "83/83 - 0s - loss: 801.2565 - val_loss: 478.6007\n",
      "Epoch 913/1000\n",
      "83/83 - 0s - loss: 800.6574 - val_loss: 478.1783\n",
      "Epoch 914/1000\n",
      "83/83 - 0s - loss: 800.6636 - val_loss: 477.7648\n",
      "Epoch 915/1000\n",
      "83/83 - 0s - loss: 800.1026 - val_loss: 477.3416\n",
      "Epoch 916/1000\n",
      "83/83 - 0s - loss: 800.2698 - val_loss: 476.9333\n",
      "Epoch 917/1000\n",
      "83/83 - 0s - loss: 799.6425 - val_loss: 476.5155\n",
      "Epoch 918/1000\n",
      "83/83 - 0s - loss: 799.3753 - val_loss: 476.0956\n",
      "Epoch 919/1000\n",
      "83/83 - 0s - loss: 799.0797 - val_loss: 475.6777\n",
      "Epoch 920/1000\n",
      "83/83 - 0s - loss: 799.1205 - val_loss: 475.2707\n",
      "Epoch 921/1000\n",
      "83/83 - 0s - loss: 798.3334 - val_loss: 474.8495\n",
      "Epoch 922/1000\n",
      "83/83 - 0s - loss: 798.1440 - val_loss: 474.4299\n",
      "Epoch 923/1000\n",
      "83/83 - 0s - loss: 798.1538 - val_loss: 474.0124\n",
      "Epoch 924/1000\n",
      "83/83 - 0s - loss: 797.8744 - val_loss: 473.5944\n",
      "Epoch 925/1000\n",
      "83/83 - 0s - loss: 797.5325 - val_loss: 473.1715\n",
      "Epoch 926/1000\n",
      "83/83 - 0s - loss: 798.0353 - val_loss: 472.7931\n",
      "Epoch 927/1000\n",
      "83/83 - 0s - loss: 796.1926 - val_loss: 472.3436\n",
      "Epoch 928/1000\n",
      "83/83 - 0s - loss: 797.1319 - val_loss: 471.9688\n",
      "Epoch 929/1000\n",
      "83/83 - 0s - loss: 795.2225 - val_loss: 471.5036\n",
      "Epoch 930/1000\n",
      "83/83 - 0s - loss: 796.9547 - val_loss: 471.1300\n",
      "Epoch 931/1000\n",
      "83/83 - 0s - loss: 794.8358 - val_loss: 470.6750\n",
      "Epoch 932/1000\n",
      "83/83 - 0s - loss: 796.0352 - val_loss: 470.3021\n",
      "Epoch 933/1000\n",
      "83/83 - 0s - loss: 793.9862 - val_loss: 469.8372\n",
      "Epoch 934/1000\n",
      "83/83 - 0s - loss: 795.7987 - val_loss: 469.4629\n",
      "Epoch 935/1000\n",
      "83/83 - 0s - loss: 793.5294 - val_loss: 469.0116\n",
      "Epoch 936/1000\n",
      "83/83 - 0s - loss: 794.6672 - val_loss: 468.6189\n",
      "Epoch 937/1000\n",
      "83/83 - 0s - loss: 793.3009 - val_loss: 468.1787\n",
      "Epoch 938/1000\n",
      "83/83 - 0s - loss: 794.0546 - val_loss: 467.8097\n",
      "Epoch 939/1000\n",
      "83/83 - 0s - loss: 793.0071 - val_loss: 467.3411\n",
      "Epoch 940/1000\n",
      "83/83 - 0s - loss: 794.5719 - val_loss: 466.9776\n",
      "Epoch 941/1000\n",
      "83/83 - 1s - loss: 792.5450 - val_loss: 466.5162\n",
      "Epoch 942/1000\n",
      "83/83 - 0s - loss: 794.0839 - val_loss: 466.1470\n",
      "Epoch 943/1000\n",
      "83/83 - 0s - loss: 791.6367 - val_loss: 465.7036\n",
      "Epoch 944/1000\n",
      "83/83 - 0s - loss: 793.2778 - val_loss: 465.3256\n",
      "Epoch 945/1000\n",
      "83/83 - 0s - loss: 791.1354 - val_loss: 464.8797\n",
      "Epoch 946/1000\n",
      "83/83 - 0s - loss: 792.2167 - val_loss: 464.4929\n",
      "Epoch 947/1000\n",
      "83/83 - 0s - loss: 790.5721 - val_loss: 464.0606\n",
      "Epoch 948/1000\n",
      "83/83 - 0s - loss: 791.2188 - val_loss: 463.6792\n",
      "Epoch 949/1000\n",
      "83/83 - 0s - loss: 789.7963 - val_loss: 463.2306\n",
      "Epoch 950/1000\n",
      "83/83 - 0s - loss: 790.9208 - val_loss: 462.8593\n",
      "Epoch 951/1000\n",
      "83/83 - 0s - loss: 788.9943 - val_loss: 462.4004\n",
      "Epoch 952/1000\n",
      "83/83 - 0s - loss: 790.8012 - val_loss: 462.0535\n",
      "Epoch 953/1000\n",
      "83/83 - 0s - loss: 788.1013 - val_loss: 461.5728\n",
      "Epoch 954/1000\n",
      "83/83 - 0s - loss: 790.3116 - val_loss: 461.2602\n",
      "Epoch 955/1000\n",
      "83/83 - 0s - loss: 787.6611 - val_loss: 460.7460\n",
      "Epoch 956/1000\n",
      "83/83 - 0s - loss: 790.1014 - val_loss: 460.3985\n",
      "Epoch 957/1000\n",
      "83/83 - 0s - loss: 786.7660 - val_loss: 459.9311\n",
      "Epoch 958/1000\n",
      "83/83 - 0s - loss: 788.2725 - val_loss: 459.5551\n",
      "Epoch 959/1000\n",
      "83/83 - 0s - loss: 786.3779 - val_loss: 459.0999\n",
      "Epoch 960/1000\n",
      "83/83 - 0s - loss: 787.7393 - val_loss: 458.7229\n",
      "Epoch 961/1000\n",
      "83/83 - 0s - loss: 785.8224 - val_loss: 458.2682\n",
      "Epoch 962/1000\n",
      "83/83 - 0s - loss: 787.1439 - val_loss: 457.8865\n",
      "Epoch 963/1000\n",
      "83/83 - 0s - loss: 785.3257 - val_loss: 457.4379\n",
      "Epoch 964/1000\n",
      "83/83 - 0s - loss: 786.6063 - val_loss: 457.0751\n",
      "Epoch 965/1000\n",
      "83/83 - 0s - loss: 784.4078 - val_loss: 456.6005\n",
      "Epoch 966/1000\n",
      "83/83 - 0s - loss: 786.4756 - val_loss: 456.2325\n",
      "Epoch 967/1000\n",
      "83/83 - 0s - loss: 784.2029 - val_loss: 455.7789\n",
      "Epoch 968/1000\n",
      "83/83 - 0s - loss: 785.4027 - val_loss: 455.4299\n",
      "Epoch 969/1000\n",
      "83/83 - 0s - loss: 783.5024 - val_loss: 454.9428\n",
      "Epoch 970/1000\n",
      "83/83 - 0s - loss: 785.5970 - val_loss: 454.6321\n",
      "Epoch 971/1000\n",
      "83/83 - 0s - loss: 782.9520 - val_loss: 454.1164\n",
      "Epoch 972/1000\n",
      "83/83 - 1s - loss: 785.4962 - val_loss: 453.8575\n",
      "Epoch 973/1000\n",
      "83/83 - 0s - loss: 781.9850 - val_loss: 453.2929\n",
      "Epoch 974/1000\n",
      "83/83 - 0s - loss: 785.1791 - val_loss: 452.9442\n",
      "Epoch 975/1000\n",
      "83/83 - 1s - loss: 781.6313 - val_loss: 452.4853\n",
      "Epoch 976/1000\n",
      "83/83 - 0s - loss: 783.2293 - val_loss: 452.1060\n",
      "Epoch 977/1000\n",
      "83/83 - 0s - loss: 781.5975 - val_loss: 451.6664\n",
      "Epoch 978/1000\n",
      "83/83 - 0s - loss: 784.0531 - val_loss: 451.3120\n",
      "Epoch 979/1000\n",
      "83/83 - 0s - loss: 781.2944 - val_loss: 450.8310\n",
      "Epoch 980/1000\n",
      "83/83 - 0s - loss: 782.2171 - val_loss: 450.4364\n",
      "Epoch 981/1000\n",
      "83/83 - 0s - loss: 780.6788 - val_loss: 450.0208\n",
      "Epoch 982/1000\n",
      "83/83 - 1s - loss: 780.4117 - val_loss: 449.6072\n",
      "Epoch 983/1000\n",
      "83/83 - 0s - loss: 779.8884 - val_loss: 449.1835\n",
      "Epoch 984/1000\n",
      "83/83 - 0s - loss: 779.9193 - val_loss: 448.7700\n",
      "Epoch 985/1000\n",
      "83/83 - 0s - loss: 779.5837 - val_loss: 448.3536\n",
      "Epoch 986/1000\n",
      "83/83 - 1s - loss: 779.2887 - val_loss: 447.9374\n",
      "Epoch 987/1000\n",
      "83/83 - 0s - loss: 779.0054 - val_loss: 447.5208\n",
      "Epoch 988/1000\n",
      "83/83 - 1s - loss: 778.6942 - val_loss: 447.1039\n",
      "Epoch 989/1000\n",
      "83/83 - 0s - loss: 778.4290 - val_loss: 446.6872\n",
      "Epoch 990/1000\n",
      "83/83 - 0s - loss: 778.1409 - val_loss: 446.2704\n",
      "Epoch 991/1000\n",
      "83/83 - 0s - loss: 777.8532 - val_loss: 445.8535\n",
      "Epoch 992/1000\n",
      "83/83 - 0s - loss: 777.5035 - val_loss: 445.4355\n",
      "Epoch 993/1000\n",
      "83/83 - 0s - loss: 777.2631 - val_loss: 445.0178\n",
      "Epoch 994/1000\n",
      "83/83 - 0s - loss: 776.9883 - val_loss: 444.6006\n",
      "Epoch 995/1000\n",
      "83/83 - 0s - loss: 776.6829 - val_loss: 444.1829\n",
      "Epoch 996/1000\n",
      "83/83 - 0s - loss: 776.3984 - val_loss: 443.7655\n",
      "Epoch 997/1000\n",
      "83/83 - 0s - loss: 776.0985 - val_loss: 443.3485\n",
      "Epoch 998/1000\n",
      "83/83 - 0s - loss: 776.3163 - val_loss: 442.9398\n",
      "Epoch 999/1000\n",
      "83/83 - 0s - loss: 775.5479 - val_loss: 442.5060\n",
      "Epoch 1000/1000\n",
      "83/83 - 0s - loss: 775.9108 - val_loss: 442.1209\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM model untuk seasonal\n",
    "model = Sequential()\n",
    "model.add(LSTM(jumlah_neuron, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=epooch_total, batch_size=size_batch, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282.5008 ],\n",
       "       [282.60278],\n",
       "       [282.60278],\n",
       "       [282.60278],\n",
       "       [282.60278],\n",
       "       [282.60278],\n",
       "       [282.60275],\n",
       "       [282.4679 ],\n",
       "       [282.60263],\n",
       "       [282.60278]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[282.50079345703125,\n",
       " 282.602783203125,\n",
       " 282.602783203125,\n",
       " 282.602783203125,\n",
       " 282.602783203125,\n",
       " 282.602783203125,\n",
       " 282.6027526855469,\n",
       " 282.4678955078125,\n",
       " 282.6026306152344,\n",
       " 282.602783203125]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jadikan list semua hasil prediksi\n",
    "hasil_lstm = ndarray.tolist(yhat)\n",
    "list_evaluasi = data_evaluasi['case'].tolist()\n",
    "length = len(list_evaluasi)\n",
    "hasil_final = list()\n",
    "\n",
    "for i in range(length):\n",
    "    result_single = hasil_lstm[i]\n",
    "    result_single = result_single[0]\n",
    "    tambah = result_single\n",
    "    hasil_final.append(tambah)\n",
    "    #print('hasil tambah',tambah)\n",
    "\n",
    "hasil_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213171.52313217949"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(list_evaluasi, hasil_final)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461.70501744315004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mean_squared_error(list_evaluasi, hasil_final, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442.1209228515625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(list_evaluasi, hasil_final)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
